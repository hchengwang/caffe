I0819 23:09:17.188840 16291 caffe.cpp:185] Using GPUs 0
I0819 23:09:17.304859 16291 caffe.cpp:190] GPU 0: GeForce GTX TITAN X
I0819 23:09:17.948338 16291 solver.cpp:48] Initializing solver from parameters: 
test_iter: 750
test_interval: 4000
base_lr: 0.01
display: 500
max_iter: 8000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 2000
snapshot: 4000
snapshot_prefix: "examples/jr-station/vgg"
solver_mode: GPU
device_id: 0
net: "examples/jr-station/part_Dict.prototxt"
I0819 23:09:17.949159 16291 solver.cpp:91] Creating training net from net file: examples/jr-station/part_Dict.prototxt
I0819 23:09:17.949651 16291 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0819 23:09:17.949806 16291 net.cpp:49] Initializing net from parameters: 
name: "Bigram_Net_VGG"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
  }
  data_param {
    source: "examples/jr-station/img_part_train_lmdb"
    batch_size: 500
    backend: LMDB
  }
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 100
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3_5"
  type: "Convolution"
  bottom: "conv3"
  top: "conv3_5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_5"
  type: "ReLU"
  bottom: "conv3_5"
  top: "conv3_5"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_5"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "fc1"
  type: "Convolution"
  bottom: "conv4"
  top: "fc1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 4096
    pad: 0
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    kernel_h: 4
    kernel_w: 13
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "fc1"
  top: "fc1"
}
layer {
  name: "fc2"
  type: "Convolution"
  bottom: "fc1"
  top: "fc2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 4096
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc2"
  top: "fc2"
}
layer {
  name: "fc_class"
  type: "Convolution"
  bottom: "fc2"
  top: "fc_class"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 88172
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc_class"
  top: "prob"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc_class"
  bottom: "label"
  top: "loss"
}
I0819 23:09:17.949893 16291 layer_factory.hpp:77] Creating layer data
I0819 23:09:18.004282 16291 net.cpp:91] Creating Layer data
I0819 23:09:18.004300 16291 net.cpp:399] data -> data
I0819 23:09:18.004322 16291 net.cpp:399] data -> label
I0819 23:09:18.004863 16300 db_lmdb.cpp:35] Opened lmdb examples/jr-station/img_part_train_lmdb
I0819 23:09:18.386404 16291 data_layer.cpp:41] output data size: 500,1,32,100
I0819 23:09:18.393753 16291 net.cpp:141] Setting up data
I0819 23:09:18.393777 16291 net.cpp:148] Top shape: 500 1 32 100 (1600000)
I0819 23:09:18.393782 16291 net.cpp:148] Top shape: 500 (500)
I0819 23:09:18.393785 16291 net.cpp:156] Memory required for data: 6402000
I0819 23:09:18.393791 16291 layer_factory.hpp:77] Creating layer conv1
I0819 23:09:18.393813 16291 net.cpp:91] Creating Layer conv1
I0819 23:09:18.393817 16291 net.cpp:425] conv1 <- data
I0819 23:09:18.393828 16291 net.cpp:399] conv1 -> conv1
I0819 23:09:18.430598 16302 blocking_queue.cpp:50] Waiting for data
I0819 23:09:19.992656 16291 net.cpp:141] Setting up conv1
I0819 23:09:19.992676 16291 net.cpp:148] Top shape: 500 64 32 100 (102400000)
I0819 23:09:19.992681 16291 net.cpp:156] Memory required for data: 416002000
I0819 23:09:19.992691 16291 layer_factory.hpp:77] Creating layer relu1
I0819 23:09:19.992700 16291 net.cpp:91] Creating Layer relu1
I0819 23:09:19.992703 16291 net.cpp:425] relu1 <- conv1
I0819 23:09:19.992708 16291 net.cpp:386] relu1 -> conv1 (in-place)
I0819 23:09:19.996819 16291 net.cpp:141] Setting up relu1
I0819 23:09:19.996830 16291 net.cpp:148] Top shape: 500 64 32 100 (102400000)
I0819 23:09:19.996834 16291 net.cpp:156] Memory required for data: 825602000
I0819 23:09:19.996836 16291 layer_factory.hpp:77] Creating layer pool1
I0819 23:09:19.996841 16291 net.cpp:91] Creating Layer pool1
I0819 23:09:19.996845 16291 net.cpp:425] pool1 <- conv1
I0819 23:09:19.996848 16291 net.cpp:399] pool1 -> pool1
I0819 23:09:19.997305 16291 net.cpp:141] Setting up pool1
I0819 23:09:19.997315 16291 net.cpp:148] Top shape: 500 64 16 50 (25600000)
I0819 23:09:19.997319 16291 net.cpp:156] Memory required for data: 928002000
I0819 23:09:19.997321 16291 layer_factory.hpp:77] Creating layer conv2
I0819 23:09:19.997331 16291 net.cpp:91] Creating Layer conv2
I0819 23:09:19.997334 16291 net.cpp:425] conv2 <- pool1
I0819 23:09:19.997340 16291 net.cpp:399] conv2 -> conv2
I0819 23:09:20.002435 16291 net.cpp:141] Setting up conv2
I0819 23:09:20.002446 16291 net.cpp:148] Top shape: 500 128 16 50 (51200000)
I0819 23:09:20.002449 16291 net.cpp:156] Memory required for data: 1132802000
I0819 23:09:20.002457 16291 layer_factory.hpp:77] Creating layer relu2
I0819 23:09:20.002462 16291 net.cpp:91] Creating Layer relu2
I0819 23:09:20.002465 16291 net.cpp:425] relu2 <- conv2
I0819 23:09:20.002478 16291 net.cpp:386] relu2 -> conv2 (in-place)
I0819 23:09:20.002588 16291 net.cpp:141] Setting up relu2
I0819 23:09:20.002594 16291 net.cpp:148] Top shape: 500 128 16 50 (51200000)
I0819 23:09:20.002598 16291 net.cpp:156] Memory required for data: 1337602000
I0819 23:09:20.002599 16291 layer_factory.hpp:77] Creating layer pool2
I0819 23:09:20.002604 16291 net.cpp:91] Creating Layer pool2
I0819 23:09:20.002606 16291 net.cpp:425] pool2 <- conv2
I0819 23:09:20.002610 16291 net.cpp:399] pool2 -> pool2
I0819 23:09:20.002637 16291 net.cpp:141] Setting up pool2
I0819 23:09:20.002641 16291 net.cpp:148] Top shape: 500 128 8 25 (12800000)
I0819 23:09:20.002645 16291 net.cpp:156] Memory required for data: 1388802000
I0819 23:09:20.002646 16291 layer_factory.hpp:77] Creating layer conv3
I0819 23:09:20.002653 16291 net.cpp:91] Creating Layer conv3
I0819 23:09:20.002657 16291 net.cpp:425] conv3 <- pool2
I0819 23:09:20.002662 16291 net.cpp:399] conv3 -> conv3
I0819 23:09:20.024950 16291 net.cpp:141] Setting up conv3
I0819 23:09:20.024968 16291 net.cpp:148] Top shape: 500 256 8 25 (25600000)
I0819 23:09:20.024972 16291 net.cpp:156] Memory required for data: 1491202000
I0819 23:09:20.024981 16291 layer_factory.hpp:77] Creating layer relu3
I0819 23:09:20.024988 16291 net.cpp:91] Creating Layer relu3
I0819 23:09:20.024991 16291 net.cpp:425] relu3 <- conv3
I0819 23:09:20.024996 16291 net.cpp:386] relu3 -> conv3 (in-place)
I0819 23:09:20.025130 16291 net.cpp:141] Setting up relu3
I0819 23:09:20.025137 16291 net.cpp:148] Top shape: 500 256 8 25 (25600000)
I0819 23:09:20.025141 16291 net.cpp:156] Memory required for data: 1593602000
I0819 23:09:20.025143 16291 layer_factory.hpp:77] Creating layer conv3_5
I0819 23:09:20.025151 16291 net.cpp:91] Creating Layer conv3_5
I0819 23:09:20.025154 16291 net.cpp:425] conv3_5 <- conv3
I0819 23:09:20.025161 16291 net.cpp:399] conv3_5 -> conv3_5
I0819 23:09:20.050875 16291 net.cpp:141] Setting up conv3_5
I0819 23:09:20.050894 16291 net.cpp:148] Top shape: 500 512 8 25 (51200000)
I0819 23:09:20.050897 16291 net.cpp:156] Memory required for data: 1798402000
I0819 23:09:20.050904 16291 layer_factory.hpp:77] Creating layer relu3_5
I0819 23:09:20.050910 16291 net.cpp:91] Creating Layer relu3_5
I0819 23:09:20.050914 16291 net.cpp:425] relu3_5 <- conv3_5
I0819 23:09:20.050917 16291 net.cpp:386] relu3_5 -> conv3_5 (in-place)
I0819 23:09:20.051115 16291 net.cpp:141] Setting up relu3_5
I0819 23:09:20.051123 16291 net.cpp:148] Top shape: 500 512 8 25 (51200000)
I0819 23:09:20.051126 16291 net.cpp:156] Memory required for data: 2003202000
I0819 23:09:20.051128 16291 layer_factory.hpp:77] Creating layer pool3
I0819 23:09:20.051134 16291 net.cpp:91] Creating Layer pool3
I0819 23:09:20.051136 16291 net.cpp:425] pool3 <- conv3_5
I0819 23:09:20.051141 16291 net.cpp:399] pool3 -> pool3
I0819 23:09:20.051173 16291 net.cpp:141] Setting up pool3
I0819 23:09:20.051178 16291 net.cpp:148] Top shape: 500 512 4 13 (13312000)
I0819 23:09:20.051182 16291 net.cpp:156] Memory required for data: 2056450000
I0819 23:09:20.051183 16291 layer_factory.hpp:77] Creating layer conv4
I0819 23:09:20.051190 16291 net.cpp:91] Creating Layer conv4
I0819 23:09:20.051193 16291 net.cpp:425] conv4 <- pool3
I0819 23:09:20.051198 16291 net.cpp:399] conv4 -> conv4
I0819 23:09:20.100044 16291 net.cpp:141] Setting up conv4
I0819 23:09:20.100064 16291 net.cpp:148] Top shape: 500 512 4 13 (13312000)
I0819 23:09:20.100067 16291 net.cpp:156] Memory required for data: 2109698000
I0819 23:09:20.100075 16291 layer_factory.hpp:77] Creating layer relu4
I0819 23:09:20.100083 16291 net.cpp:91] Creating Layer relu4
I0819 23:09:20.100086 16291 net.cpp:425] relu4 <- conv4
I0819 23:09:20.100091 16291 net.cpp:386] relu4 -> conv4 (in-place)
I0819 23:09:20.100208 16291 net.cpp:141] Setting up relu4
I0819 23:09:20.100215 16291 net.cpp:148] Top shape: 500 512 4 13 (13312000)
I0819 23:09:20.100219 16291 net.cpp:156] Memory required for data: 2162946000
I0819 23:09:20.100220 16291 layer_factory.hpp:77] Creating layer fc1
I0819 23:09:20.100239 16291 net.cpp:91] Creating Layer fc1
I0819 23:09:20.100242 16291 net.cpp:425] fc1 <- conv4
I0819 23:09:20.100246 16291 net.cpp:399] fc1 -> fc1
I0819 23:09:22.315060 16291 net.cpp:141] Setting up fc1
I0819 23:09:22.315083 16291 net.cpp:148] Top shape: 500 4096 1 1 (2048000)
I0819 23:09:22.315085 16291 net.cpp:156] Memory required for data: 2171138000
I0819 23:09:22.315091 16291 layer_factory.hpp:77] Creating layer relu5
I0819 23:09:22.315099 16291 net.cpp:91] Creating Layer relu5
I0819 23:09:22.315101 16291 net.cpp:425] relu5 <- fc1
I0819 23:09:22.315109 16291 net.cpp:386] relu5 -> fc1 (in-place)
I0819 23:09:22.315227 16291 net.cpp:141] Setting up relu5
I0819 23:09:22.315235 16291 net.cpp:148] Top shape: 500 4096 1 1 (2048000)
I0819 23:09:22.315238 16291 net.cpp:156] Memory required for data: 2179330000
I0819 23:09:22.315242 16291 layer_factory.hpp:77] Creating layer fc2
I0819 23:09:22.315250 16291 net.cpp:91] Creating Layer fc2
I0819 23:09:22.315253 16291 net.cpp:425] fc2 <- fc1
I0819 23:09:22.315258 16291 net.cpp:399] fc2 -> fc2
I0819 23:09:22.659920 16291 net.cpp:141] Setting up fc2
I0819 23:09:22.659941 16291 net.cpp:148] Top shape: 500 4096 1 1 (2048000)
I0819 23:09:22.659945 16291 net.cpp:156] Memory required for data: 2187522000
I0819 23:09:22.659950 16291 layer_factory.hpp:77] Creating layer relu6
I0819 23:09:22.659960 16291 net.cpp:91] Creating Layer relu6
I0819 23:09:22.659965 16291 net.cpp:425] relu6 <- fc2
I0819 23:09:22.659968 16291 net.cpp:386] relu6 -> fc2 (in-place)
I0819 23:09:22.660167 16291 net.cpp:141] Setting up relu6
I0819 23:09:22.660176 16291 net.cpp:148] Top shape: 500 4096 1 1 (2048000)
I0819 23:09:22.660179 16291 net.cpp:156] Memory required for data: 2195714000
I0819 23:09:22.660181 16291 layer_factory.hpp:77] Creating layer fc_class
I0819 23:09:22.660190 16291 net.cpp:91] Creating Layer fc_class
I0819 23:09:22.660193 16291 net.cpp:425] fc_class <- fc2
I0819 23:09:22.660197 16291 net.cpp:399] fc_class -> fc_class
I0819 23:09:30.027220 16291 net.cpp:141] Setting up fc_class
I0819 23:09:30.027240 16291 net.cpp:148] Top shape: 500 88172 1 1 (44086000)
I0819 23:09:30.027245 16291 net.cpp:156] Memory required for data: 2372058000
I0819 23:09:30.027251 16291 layer_factory.hpp:77] Creating layer fc_class_fc_class_0_split
I0819 23:09:30.027256 16291 net.cpp:91] Creating Layer fc_class_fc_class_0_split
I0819 23:09:30.027259 16291 net.cpp:425] fc_class_fc_class_0_split <- fc_class
I0819 23:09:30.027264 16291 net.cpp:399] fc_class_fc_class_0_split -> fc_class_fc_class_0_split_0
I0819 23:09:30.027271 16291 net.cpp:399] fc_class_fc_class_0_split -> fc_class_fc_class_0_split_1
I0819 23:09:30.027298 16291 net.cpp:141] Setting up fc_class_fc_class_0_split
I0819 23:09:30.027303 16291 net.cpp:148] Top shape: 500 88172 1 1 (44086000)
I0819 23:09:30.027307 16291 net.cpp:148] Top shape: 500 88172 1 1 (44086000)
I0819 23:09:30.027308 16291 net.cpp:156] Memory required for data: 2724746000
I0819 23:09:30.027310 16291 layer_factory.hpp:77] Creating layer prob
I0819 23:09:30.027314 16291 net.cpp:91] Creating Layer prob
I0819 23:09:30.027317 16291 net.cpp:425] prob <- fc_class_fc_class_0_split_0
I0819 23:09:30.027320 16291 net.cpp:399] prob -> prob
I0819 23:09:30.027509 16291 net.cpp:141] Setting up prob
I0819 23:09:30.027515 16291 net.cpp:148] Top shape: 500 88172 1 1 (44086000)
I0819 23:09:30.027518 16291 net.cpp:156] Memory required for data: 2901090000
I0819 23:09:30.027520 16291 layer_factory.hpp:77] Creating layer loss
I0819 23:09:30.027524 16291 net.cpp:91] Creating Layer loss
I0819 23:09:30.027528 16291 net.cpp:425] loss <- fc_class_fc_class_0_split_1
I0819 23:09:30.027530 16291 net.cpp:425] loss <- label
I0819 23:09:30.027534 16291 net.cpp:399] loss -> loss
I0819 23:09:30.027541 16291 layer_factory.hpp:77] Creating layer loss
I0819 23:09:30.077512 16291 net.cpp:141] Setting up loss
I0819 23:09:30.077533 16291 net.cpp:148] Top shape: (1)
I0819 23:09:30.077535 16291 net.cpp:151]     with loss weight 1
I0819 23:09:30.077548 16291 net.cpp:156] Memory required for data: 2901090004
I0819 23:09:30.077553 16291 net.cpp:217] loss needs backward computation.
I0819 23:09:30.077572 16291 net.cpp:219] prob does not need backward computation.
I0819 23:09:30.077575 16291 net.cpp:217] fc_class_fc_class_0_split needs backward computation.
I0819 23:09:30.077577 16291 net.cpp:217] fc_class needs backward computation.
I0819 23:09:30.077580 16291 net.cpp:217] relu6 needs backward computation.
I0819 23:09:30.077582 16291 net.cpp:217] fc2 needs backward computation.
I0819 23:09:30.077587 16291 net.cpp:217] relu5 needs backward computation.
I0819 23:09:30.077590 16291 net.cpp:217] fc1 needs backward computation.
I0819 23:09:30.077592 16291 net.cpp:217] relu4 needs backward computation.
I0819 23:09:30.077595 16291 net.cpp:217] conv4 needs backward computation.
I0819 23:09:30.077597 16291 net.cpp:217] pool3 needs backward computation.
I0819 23:09:30.077600 16291 net.cpp:217] relu3_5 needs backward computation.
I0819 23:09:30.077602 16291 net.cpp:217] conv3_5 needs backward computation.
I0819 23:09:30.077605 16291 net.cpp:217] relu3 needs backward computation.
I0819 23:09:30.077606 16291 net.cpp:217] conv3 needs backward computation.
I0819 23:09:30.077610 16291 net.cpp:217] pool2 needs backward computation.
I0819 23:09:30.077612 16291 net.cpp:217] relu2 needs backward computation.
I0819 23:09:30.077615 16291 net.cpp:217] conv2 needs backward computation.
I0819 23:09:30.077617 16291 net.cpp:217] pool1 needs backward computation.
I0819 23:09:30.077620 16291 net.cpp:217] relu1 needs backward computation.
I0819 23:09:30.077621 16291 net.cpp:217] conv1 needs backward computation.
I0819 23:09:30.077625 16291 net.cpp:219] data does not need backward computation.
I0819 23:09:30.077626 16291 net.cpp:261] This network produces output loss
I0819 23:09:30.077630 16291 net.cpp:261] This network produces output prob
I0819 23:09:30.077641 16291 net.cpp:274] Network initialization done.
I0819 23:09:30.078101 16291 solver.cpp:181] Creating test net (#0) specified by net file: examples/jr-station/part_Dict.prototxt
I0819 23:09:30.078128 16291 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0819 23:09:30.078255 16291 net.cpp:49] Initializing net from parameters: 
name: "Bigram_Net_VGG"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
  }
  data_param {
    source: "examples/jr-station/img_part_test_lmdb"
    batch_size: 200
    backend: LMDB
  }
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 100
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3_5"
  type: "Convolution"
  bottom: "conv3"
  top: "conv3_5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_5"
  type: "ReLU"
  bottom: "conv3_5"
  top: "conv3_5"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_5"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "fc1"
  type: "Convolution"
  bottom: "conv4"
  top: "fc1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 4096
    pad: 0
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    kernel_h: 4
    kernel_w: 13
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "fc1"
  top: "fc1"
}
layer {
  name: "fc2"
  type: "Convolution"
  bottom: "fc1"
  top: "fc2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 4096
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc2"
  top: "fc2"
}
layer {
  name: "fc_class"
  type: "Convolution"
  bottom: "fc2"
  top: "fc_class"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 88172
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc_class"
  top: "prob"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc_class"
  bottom: "label"
  top: "loss"
}
I0819 23:09:30.078320 16291 layer_factory.hpp:77] Creating layer data
I0819 23:09:30.078433 16291 net.cpp:91] Creating Layer data
I0819 23:09:30.078440 16291 net.cpp:399] data -> data
I0819 23:09:30.078447 16291 net.cpp:399] data -> label
I0819 23:09:30.079008 16321 db_lmdb.cpp:35] Opened lmdb examples/jr-station/img_part_test_lmdb
I0819 23:09:30.079136 16291 data_layer.cpp:41] output data size: 200,1,32,100
I0819 23:09:30.082263 16291 net.cpp:141] Setting up data
I0819 23:09:30.082281 16291 net.cpp:148] Top shape: 200 1 32 100 (640000)
I0819 23:09:30.082285 16291 net.cpp:148] Top shape: 200 (200)
I0819 23:09:30.082288 16291 net.cpp:156] Memory required for data: 2560800
I0819 23:09:30.082291 16291 layer_factory.hpp:77] Creating layer conv1
I0819 23:09:30.082304 16291 net.cpp:91] Creating Layer conv1
I0819 23:09:30.082309 16291 net.cpp:425] conv1 <- data
I0819 23:09:30.082314 16291 net.cpp:399] conv1 -> conv1
I0819 23:09:30.083536 16291 net.cpp:141] Setting up conv1
I0819 23:09:30.083549 16291 net.cpp:148] Top shape: 200 64 32 100 (40960000)
I0819 23:09:30.083564 16291 net.cpp:156] Memory required for data: 166400800
I0819 23:09:30.083571 16291 layer_factory.hpp:77] Creating layer relu1
I0819 23:09:30.083585 16291 net.cpp:91] Creating Layer relu1
I0819 23:09:30.083588 16291 net.cpp:425] relu1 <- conv1
I0819 23:09:30.083601 16291 net.cpp:386] relu1 -> conv1 (in-place)
I0819 23:09:30.083809 16291 net.cpp:141] Setting up relu1
I0819 23:09:30.083818 16291 net.cpp:148] Top shape: 200 64 32 100 (40960000)
I0819 23:09:30.083822 16291 net.cpp:156] Memory required for data: 330240800
I0819 23:09:30.083823 16291 layer_factory.hpp:77] Creating layer pool1
I0819 23:09:30.083829 16291 net.cpp:91] Creating Layer pool1
I0819 23:09:30.083832 16291 net.cpp:425] pool1 <- conv1
I0819 23:09:30.083835 16291 net.cpp:399] pool1 -> pool1
I0819 23:09:30.083865 16291 net.cpp:141] Setting up pool1
I0819 23:09:30.083870 16291 net.cpp:148] Top shape: 200 64 16 50 (10240000)
I0819 23:09:30.083873 16291 net.cpp:156] Memory required for data: 371200800
I0819 23:09:30.083874 16291 layer_factory.hpp:77] Creating layer conv2
I0819 23:09:30.083883 16291 net.cpp:91] Creating Layer conv2
I0819 23:09:30.083884 16291 net.cpp:425] conv2 <- pool1
I0819 23:09:30.083890 16291 net.cpp:399] conv2 -> conv2
I0819 23:09:30.089434 16291 net.cpp:141] Setting up conv2
I0819 23:09:30.089448 16291 net.cpp:148] Top shape: 200 128 16 50 (20480000)
I0819 23:09:30.089453 16291 net.cpp:156] Memory required for data: 453120800
I0819 23:09:30.089462 16291 layer_factory.hpp:77] Creating layer relu2
I0819 23:09:30.089468 16291 net.cpp:91] Creating Layer relu2
I0819 23:09:30.089471 16291 net.cpp:425] relu2 <- conv2
I0819 23:09:30.089475 16291 net.cpp:386] relu2 -> conv2 (in-place)
I0819 23:09:30.089588 16291 net.cpp:141] Setting up relu2
I0819 23:09:30.089596 16291 net.cpp:148] Top shape: 200 128 16 50 (20480000)
I0819 23:09:30.089598 16291 net.cpp:156] Memory required for data: 535040800
I0819 23:09:30.089601 16291 layer_factory.hpp:77] Creating layer pool2
I0819 23:09:30.089607 16291 net.cpp:91] Creating Layer pool2
I0819 23:09:30.089608 16291 net.cpp:425] pool2 <- conv2
I0819 23:09:30.089612 16291 net.cpp:399] pool2 -> pool2
I0819 23:09:30.089642 16291 net.cpp:141] Setting up pool2
I0819 23:09:30.089646 16291 net.cpp:148] Top shape: 200 128 8 25 (5120000)
I0819 23:09:30.089649 16291 net.cpp:156] Memory required for data: 555520800
I0819 23:09:30.089651 16291 layer_factory.hpp:77] Creating layer conv3
I0819 23:09:30.089658 16291 net.cpp:91] Creating Layer conv3
I0819 23:09:30.089661 16291 net.cpp:425] conv3 <- pool2
I0819 23:09:30.089668 16291 net.cpp:399] conv3 -> conv3
I0819 23:09:30.096714 16291 net.cpp:141] Setting up conv3
I0819 23:09:30.096729 16291 net.cpp:148] Top shape: 200 256 8 25 (10240000)
I0819 23:09:30.096731 16291 net.cpp:156] Memory required for data: 596480800
I0819 23:09:30.096740 16291 layer_factory.hpp:77] Creating layer relu3
I0819 23:09:30.096747 16291 net.cpp:91] Creating Layer relu3
I0819 23:09:30.096750 16291 net.cpp:425] relu3 <- conv3
I0819 23:09:30.096755 16291 net.cpp:386] relu3 -> conv3 (in-place)
I0819 23:09:30.096945 16291 net.cpp:141] Setting up relu3
I0819 23:09:30.096952 16291 net.cpp:148] Top shape: 200 256 8 25 (10240000)
I0819 23:09:30.096956 16291 net.cpp:156] Memory required for data: 637440800
I0819 23:09:30.096958 16291 layer_factory.hpp:77] Creating layer conv3_5
I0819 23:09:30.096966 16291 net.cpp:91] Creating Layer conv3_5
I0819 23:09:30.096969 16291 net.cpp:425] conv3_5 <- conv3
I0819 23:09:30.096973 16291 net.cpp:399] conv3_5 -> conv3_5
I0819 23:09:30.122143 16291 net.cpp:141] Setting up conv3_5
I0819 23:09:30.122162 16291 net.cpp:148] Top shape: 200 512 8 25 (20480000)
I0819 23:09:30.122166 16291 net.cpp:156] Memory required for data: 719360800
I0819 23:09:30.122172 16291 layer_factory.hpp:77] Creating layer relu3_5
I0819 23:09:30.122179 16291 net.cpp:91] Creating Layer relu3_5
I0819 23:09:30.122181 16291 net.cpp:425] relu3_5 <- conv3_5
I0819 23:09:30.122186 16291 net.cpp:386] relu3_5 -> conv3_5 (in-place)
I0819 23:09:30.122372 16291 net.cpp:141] Setting up relu3_5
I0819 23:09:30.122380 16291 net.cpp:148] Top shape: 200 512 8 25 (20480000)
I0819 23:09:30.122382 16291 net.cpp:156] Memory required for data: 801280800
I0819 23:09:30.122385 16291 layer_factory.hpp:77] Creating layer pool3
I0819 23:09:30.122400 16291 net.cpp:91] Creating Layer pool3
I0819 23:09:30.122402 16291 net.cpp:425] pool3 <- conv3_5
I0819 23:09:30.122406 16291 net.cpp:399] pool3 -> pool3
I0819 23:09:30.122442 16291 net.cpp:141] Setting up pool3
I0819 23:09:30.122447 16291 net.cpp:148] Top shape: 200 512 4 13 (5324800)
I0819 23:09:30.122449 16291 net.cpp:156] Memory required for data: 822580000
I0819 23:09:30.122452 16291 layer_factory.hpp:77] Creating layer conv4
I0819 23:09:30.122459 16291 net.cpp:91] Creating Layer conv4
I0819 23:09:30.122462 16291 net.cpp:425] conv4 <- pool3
I0819 23:09:30.122467 16291 net.cpp:399] conv4 -> conv4
I0819 23:09:30.170976 16291 net.cpp:141] Setting up conv4
I0819 23:09:30.170994 16291 net.cpp:148] Top shape: 200 512 4 13 (5324800)
I0819 23:09:30.170999 16291 net.cpp:156] Memory required for data: 843879200
I0819 23:09:30.171006 16291 layer_factory.hpp:77] Creating layer relu4
I0819 23:09:30.171015 16291 net.cpp:91] Creating Layer relu4
I0819 23:09:30.171017 16291 net.cpp:425] relu4 <- conv4
I0819 23:09:30.171021 16291 net.cpp:386] relu4 -> conv4 (in-place)
I0819 23:09:30.171133 16291 net.cpp:141] Setting up relu4
I0819 23:09:30.171139 16291 net.cpp:148] Top shape: 200 512 4 13 (5324800)
I0819 23:09:30.171141 16291 net.cpp:156] Memory required for data: 865178400
I0819 23:09:30.171144 16291 layer_factory.hpp:77] Creating layer fc1
I0819 23:09:30.171151 16291 net.cpp:91] Creating Layer fc1
I0819 23:09:30.171154 16291 net.cpp:425] fc1 <- conv4
I0819 23:09:30.171159 16291 net.cpp:399] fc1 -> fc1
I0819 23:09:32.383044 16291 net.cpp:141] Setting up fc1
I0819 23:09:32.383065 16291 net.cpp:148] Top shape: 200 4096 1 1 (819200)
I0819 23:09:32.383069 16291 net.cpp:156] Memory required for data: 868455200
I0819 23:09:32.383074 16291 layer_factory.hpp:77] Creating layer relu5
I0819 23:09:32.383081 16291 net.cpp:91] Creating Layer relu5
I0819 23:09:32.383085 16291 net.cpp:425] relu5 <- fc1
I0819 23:09:32.383090 16291 net.cpp:386] relu5 -> fc1 (in-place)
I0819 23:09:32.383277 16291 net.cpp:141] Setting up relu5
I0819 23:09:32.383285 16291 net.cpp:148] Top shape: 200 4096 1 1 (819200)
I0819 23:09:32.383288 16291 net.cpp:156] Memory required for data: 871732000
I0819 23:09:32.383291 16291 layer_factory.hpp:77] Creating layer fc2
I0819 23:09:32.383303 16291 net.cpp:91] Creating Layer fc2
I0819 23:09:32.383306 16291 net.cpp:425] fc2 <- fc1
I0819 23:09:32.383311 16291 net.cpp:399] fc2 -> fc2
I0819 23:09:32.724434 16291 net.cpp:141] Setting up fc2
I0819 23:09:32.724453 16291 net.cpp:148] Top shape: 200 4096 1 1 (819200)
I0819 23:09:32.724457 16291 net.cpp:156] Memory required for data: 875008800
I0819 23:09:32.724463 16291 layer_factory.hpp:77] Creating layer relu6
I0819 23:09:32.724470 16291 net.cpp:91] Creating Layer relu6
I0819 23:09:32.724473 16291 net.cpp:425] relu6 <- fc2
I0819 23:09:32.724478 16291 net.cpp:386] relu6 -> fc2 (in-place)
I0819 23:09:32.724661 16291 net.cpp:141] Setting up relu6
I0819 23:09:32.724669 16291 net.cpp:148] Top shape: 200 4096 1 1 (819200)
I0819 23:09:32.724673 16291 net.cpp:156] Memory required for data: 878285600
I0819 23:09:32.724674 16291 layer_factory.hpp:77] Creating layer fc_class
I0819 23:09:32.724683 16291 net.cpp:91] Creating Layer fc_class
I0819 23:09:32.724685 16291 net.cpp:425] fc_class <- fc2
I0819 23:09:32.724690 16291 net.cpp:399] fc_class -> fc_class
I0819 23:09:40.049129 16291 net.cpp:141] Setting up fc_class
I0819 23:09:40.049149 16291 net.cpp:148] Top shape: 200 88172 1 1 (17634400)
I0819 23:09:40.049154 16291 net.cpp:156] Memory required for data: 948823200
I0819 23:09:40.049160 16291 layer_factory.hpp:77] Creating layer fc_class_fc_class_0_split
I0819 23:09:40.049166 16291 net.cpp:91] Creating Layer fc_class_fc_class_0_split
I0819 23:09:40.049170 16291 net.cpp:425] fc_class_fc_class_0_split <- fc_class
I0819 23:09:40.049175 16291 net.cpp:399] fc_class_fc_class_0_split -> fc_class_fc_class_0_split_0
I0819 23:09:40.049182 16291 net.cpp:399] fc_class_fc_class_0_split -> fc_class_fc_class_0_split_1
I0819 23:09:40.049211 16291 net.cpp:141] Setting up fc_class_fc_class_0_split
I0819 23:09:40.049226 16291 net.cpp:148] Top shape: 200 88172 1 1 (17634400)
I0819 23:09:40.049229 16291 net.cpp:148] Top shape: 200 88172 1 1 (17634400)
I0819 23:09:40.049232 16291 net.cpp:156] Memory required for data: 1089898400
I0819 23:09:40.049234 16291 layer_factory.hpp:77] Creating layer prob
I0819 23:09:40.049239 16291 net.cpp:91] Creating Layer prob
I0819 23:09:40.049242 16291 net.cpp:425] prob <- fc_class_fc_class_0_split_0
I0819 23:09:40.049245 16291 net.cpp:399] prob -> prob
I0819 23:09:40.049664 16291 net.cpp:141] Setting up prob
I0819 23:09:40.049674 16291 net.cpp:148] Top shape: 200 88172 1 1 (17634400)
I0819 23:09:40.049676 16291 net.cpp:156] Memory required for data: 1160436000
I0819 23:09:40.049679 16291 layer_factory.hpp:77] Creating layer loss
I0819 23:09:40.049685 16291 net.cpp:91] Creating Layer loss
I0819 23:09:40.049687 16291 net.cpp:425] loss <- fc_class_fc_class_0_split_1
I0819 23:09:40.049690 16291 net.cpp:425] loss <- label
I0819 23:09:40.049695 16291 net.cpp:399] loss -> loss
I0819 23:09:40.049702 16291 layer_factory.hpp:77] Creating layer loss
I0819 23:09:40.070480 16291 net.cpp:141] Setting up loss
I0819 23:09:40.070500 16291 net.cpp:148] Top shape: (1)
I0819 23:09:40.070503 16291 net.cpp:151]     with loss weight 1
I0819 23:09:40.070511 16291 net.cpp:156] Memory required for data: 1160436004
I0819 23:09:40.070514 16291 net.cpp:217] loss needs backward computation.
I0819 23:09:40.070518 16291 net.cpp:219] prob does not need backward computation.
I0819 23:09:40.070521 16291 net.cpp:217] fc_class_fc_class_0_split needs backward computation.
I0819 23:09:40.070523 16291 net.cpp:217] fc_class needs backward computation.
I0819 23:09:40.070526 16291 net.cpp:217] relu6 needs backward computation.
I0819 23:09:40.070528 16291 net.cpp:217] fc2 needs backward computation.
I0819 23:09:40.070531 16291 net.cpp:217] relu5 needs backward computation.
I0819 23:09:40.070533 16291 net.cpp:217] fc1 needs backward computation.
I0819 23:09:40.070535 16291 net.cpp:217] relu4 needs backward computation.
I0819 23:09:40.070538 16291 net.cpp:217] conv4 needs backward computation.
I0819 23:09:40.070540 16291 net.cpp:217] pool3 needs backward computation.
I0819 23:09:40.070544 16291 net.cpp:217] relu3_5 needs backward computation.
I0819 23:09:40.070545 16291 net.cpp:217] conv3_5 needs backward computation.
I0819 23:09:40.070549 16291 net.cpp:217] relu3 needs backward computation.
I0819 23:09:40.070550 16291 net.cpp:217] conv3 needs backward computation.
I0819 23:09:40.070554 16291 net.cpp:217] pool2 needs backward computation.
I0819 23:09:40.070559 16291 net.cpp:217] relu2 needs backward computation.
I0819 23:09:40.070560 16291 net.cpp:217] conv2 needs backward computation.
I0819 23:09:40.070564 16291 net.cpp:217] pool1 needs backward computation.
I0819 23:09:40.070566 16291 net.cpp:217] relu1 needs backward computation.
I0819 23:09:40.070569 16291 net.cpp:217] conv1 needs backward computation.
I0819 23:09:40.070571 16291 net.cpp:219] data does not need backward computation.
I0819 23:09:40.070574 16291 net.cpp:261] This network produces output loss
I0819 23:09:40.070577 16291 net.cpp:261] This network produces output prob
I0819 23:09:40.070587 16291 net.cpp:274] Network initialization done.
I0819 23:09:40.070654 16291 solver.cpp:60] Solver scaffolding done.
I0819 23:09:40.071076 16291 caffe.cpp:129] Finetuning from examples/jr-station/pre.caffemodel
F0819 23:09:40.071104 16291 io.cpp:54] Check failed: fd != -1 (-1 vs. -1) File not found: examples/jr-station/pre.caffemodel
*** Check failure stack trace: ***
    @     0x7fef18d53daa  (unknown)
    @     0x7fef18d53ce4  (unknown)
    @     0x7fef18d536e6  (unknown)
    @     0x7fef18d56687  (unknown)
    @     0x7fef194d5d5f  caffe::ReadProtoFromBinaryFile()
    @     0x7fef194ddbd4  caffe::ReadNetParamsFromBinaryFileOrDie()
    @     0x7fef19380ca7  caffe::Net<>::CopyTrainedLayersFromBinaryProto()
    @     0x7fef19380d16  caffe::Net<>::CopyTrainedLayersFrom()
    @           0x407794  CopyLayers()
    @           0x407f95  train()
    @           0x4059bc  main
    @     0x7fef18061f45  (unknown)
    @           0x4060f1  (unknown)
    @              (nil)  (unknown)
