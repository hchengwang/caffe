I0819 23:14:58.911979 16849 caffe.cpp:185] Using GPUs 0
I0819 23:14:59.153213 16849 caffe.cpp:190] GPU 0: GeForce GTX TITAN X
I0819 23:14:59.771960 16849 solver.cpp:48] Initializing solver from parameters: 
test_iter: 750
test_interval: 4000
base_lr: 0.01
display: 500
max_iter: 8000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 2000
snapshot: 4000
snapshot_prefix: "examples/jr-station/vgg"
solver_mode: GPU
device_id: 0
net: "examples/jr-station/part_Dict.prototxt"
I0819 23:14:59.772053 16849 solver.cpp:91] Creating training net from net file: examples/jr-station/part_Dict.prototxt
I0819 23:14:59.785977 16849 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0819 23:14:59.786133 16849 net.cpp:49] Initializing net from parameters: 
name: "Bigram_Net_VGG"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
  }
  data_param {
    source: "examples/jr-station/img_part_train_lmdb"
    batch_size: 500
    backend: LMDB
  }
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 100
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3_5"
  type: "Convolution"
  bottom: "conv3"
  top: "conv3_5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_5"
  type: "ReLU"
  bottom: "conv3_5"
  top: "conv3_5"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_5"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "fc1"
  type: "Convolution"
  bottom: "conv4"
  top: "fc1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 4096
    pad: 0
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    kernel_h: 4
    kernel_w: 13
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "fc1"
  top: "fc1"
}
layer {
  name: "fc2"
  type: "Convolution"
  bottom: "fc1"
  top: "fc2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 4096
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc2"
  top: "fc2"
}
layer {
  name: "fc_class"
  type: "Convolution"
  bottom: "fc2"
  top: "fc_class"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 88172
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc_class"
  top: "prob"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc_class"
  bottom: "label"
  top: "loss"
}
I0819 23:14:59.786222 16849 layer_factory.hpp:77] Creating layer data
I0819 23:14:59.810794 16849 net.cpp:91] Creating Layer data
I0819 23:14:59.810809 16849 net.cpp:399] data -> data
I0819 23:14:59.810832 16849 net.cpp:399] data -> label
I0819 23:14:59.822629 16855 db_lmdb.cpp:35] Opened lmdb examples/jr-station/img_part_train_lmdb
I0819 23:15:00.244024 16849 data_layer.cpp:41] output data size: 500,1,32,100
I0819 23:15:00.251602 16849 net.cpp:141] Setting up data
I0819 23:15:00.251631 16849 net.cpp:148] Top shape: 500 1 32 100 (1600000)
I0819 23:15:00.251636 16849 net.cpp:148] Top shape: 500 (500)
I0819 23:15:00.251638 16849 net.cpp:156] Memory required for data: 6402000
I0819 23:15:00.251646 16849 layer_factory.hpp:77] Creating layer conv1
I0819 23:15:00.251674 16849 net.cpp:91] Creating Layer conv1
I0819 23:15:00.251680 16849 net.cpp:425] conv1 <- data
I0819 23:15:00.251694 16849 net.cpp:399] conv1 -> conv1
I0819 23:15:01.882577 16849 net.cpp:141] Setting up conv1
I0819 23:15:01.882597 16849 net.cpp:148] Top shape: 500 64 32 100 (102400000)
I0819 23:15:01.882601 16849 net.cpp:156] Memory required for data: 416002000
I0819 23:15:01.882612 16849 layer_factory.hpp:77] Creating layer relu1
I0819 23:15:01.882621 16849 net.cpp:91] Creating Layer relu1
I0819 23:15:01.882623 16849 net.cpp:425] relu1 <- conv1
I0819 23:15:01.882628 16849 net.cpp:386] relu1 -> conv1 (in-place)
I0819 23:15:01.886703 16849 net.cpp:141] Setting up relu1
I0819 23:15:01.886714 16849 net.cpp:148] Top shape: 500 64 32 100 (102400000)
I0819 23:15:01.886718 16849 net.cpp:156] Memory required for data: 825602000
I0819 23:15:01.886720 16849 layer_factory.hpp:77] Creating layer pool1
I0819 23:15:01.886726 16849 net.cpp:91] Creating Layer pool1
I0819 23:15:01.886730 16849 net.cpp:425] pool1 <- conv1
I0819 23:15:01.886734 16849 net.cpp:399] pool1 -> pool1
I0819 23:15:01.887176 16849 net.cpp:141] Setting up pool1
I0819 23:15:01.887187 16849 net.cpp:148] Top shape: 500 64 16 50 (25600000)
I0819 23:15:01.887190 16849 net.cpp:156] Memory required for data: 928002000
I0819 23:15:01.887192 16849 layer_factory.hpp:77] Creating layer conv2
I0819 23:15:01.887202 16849 net.cpp:91] Creating Layer conv2
I0819 23:15:01.887205 16849 net.cpp:425] conv2 <- pool1
I0819 23:15:01.887209 16849 net.cpp:399] conv2 -> conv2
I0819 23:15:01.892518 16849 net.cpp:141] Setting up conv2
I0819 23:15:01.892532 16849 net.cpp:148] Top shape: 500 128 16 50 (51200000)
I0819 23:15:01.892537 16849 net.cpp:156] Memory required for data: 1132802000
I0819 23:15:01.892546 16849 layer_factory.hpp:77] Creating layer relu2
I0819 23:15:01.892554 16849 net.cpp:91] Creating Layer relu2
I0819 23:15:01.892559 16849 net.cpp:425] relu2 <- conv2
I0819 23:15:01.892565 16849 net.cpp:386] relu2 -> conv2 (in-place)
I0819 23:15:01.892745 16849 net.cpp:141] Setting up relu2
I0819 23:15:01.892756 16849 net.cpp:148] Top shape: 500 128 16 50 (51200000)
I0819 23:15:01.892761 16849 net.cpp:156] Memory required for data: 1337602000
I0819 23:15:01.892765 16849 layer_factory.hpp:77] Creating layer pool2
I0819 23:15:01.892771 16849 net.cpp:91] Creating Layer pool2
I0819 23:15:01.892774 16849 net.cpp:425] pool2 <- conv2
I0819 23:15:01.892781 16849 net.cpp:399] pool2 -> pool2
I0819 23:15:01.892827 16849 net.cpp:141] Setting up pool2
I0819 23:15:01.892838 16849 net.cpp:148] Top shape: 500 128 8 25 (12800000)
I0819 23:15:01.892843 16849 net.cpp:156] Memory required for data: 1388802000
I0819 23:15:01.892848 16849 layer_factory.hpp:77] Creating layer conv3
I0819 23:15:01.892861 16849 net.cpp:91] Creating Layer conv3
I0819 23:15:01.892868 16849 net.cpp:425] conv3 <- pool2
I0819 23:15:01.892877 16849 net.cpp:399] conv3 -> conv3
I0819 23:15:01.923178 16849 net.cpp:141] Setting up conv3
I0819 23:15:01.923200 16849 net.cpp:148] Top shape: 500 256 8 25 (25600000)
I0819 23:15:01.923205 16849 net.cpp:156] Memory required for data: 1491202000
I0819 23:15:01.923216 16849 layer_factory.hpp:77] Creating layer relu3
I0819 23:15:01.923226 16849 net.cpp:91] Creating Layer relu3
I0819 23:15:01.923230 16849 net.cpp:425] relu3 <- conv3
I0819 23:15:01.923236 16849 net.cpp:386] relu3 -> conv3 (in-place)
I0819 23:15:01.923408 16849 net.cpp:141] Setting up relu3
I0819 23:15:01.923418 16849 net.cpp:148] Top shape: 500 256 8 25 (25600000)
I0819 23:15:01.923421 16849 net.cpp:156] Memory required for data: 1593602000
I0819 23:15:01.923424 16849 layer_factory.hpp:77] Creating layer conv3_5
I0819 23:15:01.923434 16849 net.cpp:91] Creating Layer conv3_5
I0819 23:15:01.923439 16849 net.cpp:425] conv3_5 <- conv3
I0819 23:15:01.923444 16849 net.cpp:399] conv3_5 -> conv3_5
I0819 23:15:01.953346 16849 net.cpp:141] Setting up conv3_5
I0819 23:15:01.953366 16849 net.cpp:148] Top shape: 500 512 8 25 (51200000)
I0819 23:15:01.953369 16849 net.cpp:156] Memory required for data: 1798402000
I0819 23:15:01.953375 16849 layer_factory.hpp:77] Creating layer relu3_5
I0819 23:15:01.953382 16849 net.cpp:91] Creating Layer relu3_5
I0819 23:15:01.953387 16849 net.cpp:425] relu3_5 <- conv3_5
I0819 23:15:01.953392 16849 net.cpp:386] relu3_5 -> conv3_5 (in-place)
I0819 23:15:01.953608 16849 net.cpp:141] Setting up relu3_5
I0819 23:15:01.953616 16849 net.cpp:148] Top shape: 500 512 8 25 (51200000)
I0819 23:15:01.953619 16849 net.cpp:156] Memory required for data: 2003202000
I0819 23:15:01.953622 16849 layer_factory.hpp:77] Creating layer pool3
I0819 23:15:01.953627 16849 net.cpp:91] Creating Layer pool3
I0819 23:15:01.953629 16849 net.cpp:425] pool3 <- conv3_5
I0819 23:15:01.953634 16849 net.cpp:399] pool3 -> pool3
I0819 23:15:01.953676 16849 net.cpp:141] Setting up pool3
I0819 23:15:01.953685 16849 net.cpp:148] Top shape: 500 512 4 13 (13312000)
I0819 23:15:01.953687 16849 net.cpp:156] Memory required for data: 2056450000
I0819 23:15:01.953690 16849 layer_factory.hpp:77] Creating layer conv4
I0819 23:15:01.953698 16849 net.cpp:91] Creating Layer conv4
I0819 23:15:01.953701 16849 net.cpp:425] conv4 <- pool3
I0819 23:15:01.953706 16849 net.cpp:399] conv4 -> conv4
I0819 23:15:02.004334 16849 net.cpp:141] Setting up conv4
I0819 23:15:02.004354 16849 net.cpp:148] Top shape: 500 512 4 13 (13312000)
I0819 23:15:02.004356 16849 net.cpp:156] Memory required for data: 2109698000
I0819 23:15:02.004365 16849 layer_factory.hpp:77] Creating layer relu4
I0819 23:15:02.004374 16849 net.cpp:91] Creating Layer relu4
I0819 23:15:02.004376 16849 net.cpp:425] relu4 <- conv4
I0819 23:15:02.004381 16849 net.cpp:386] relu4 -> conv4 (in-place)
I0819 23:15:02.004504 16849 net.cpp:141] Setting up relu4
I0819 23:15:02.004513 16849 net.cpp:148] Top shape: 500 512 4 13 (13312000)
I0819 23:15:02.004514 16849 net.cpp:156] Memory required for data: 2162946000
I0819 23:15:02.004518 16849 layer_factory.hpp:77] Creating layer fc1
I0819 23:15:02.004525 16849 net.cpp:91] Creating Layer fc1
I0819 23:15:02.004528 16849 net.cpp:425] fc1 <- conv4
I0819 23:15:02.004544 16849 net.cpp:399] fc1 -> fc1
I0819 23:15:04.223026 16849 net.cpp:141] Setting up fc1
I0819 23:15:04.223045 16849 net.cpp:148] Top shape: 500 4096 1 1 (2048000)
I0819 23:15:04.223049 16849 net.cpp:156] Memory required for data: 2171138000
I0819 23:15:04.223055 16849 layer_factory.hpp:77] Creating layer relu5
I0819 23:15:04.223062 16849 net.cpp:91] Creating Layer relu5
I0819 23:15:04.223065 16849 net.cpp:425] relu5 <- fc1
I0819 23:15:04.223069 16849 net.cpp:386] relu5 -> fc1 (in-place)
I0819 23:15:04.223182 16849 net.cpp:141] Setting up relu5
I0819 23:15:04.223189 16849 net.cpp:148] Top shape: 500 4096 1 1 (2048000)
I0819 23:15:04.223191 16849 net.cpp:156] Memory required for data: 2179330000
I0819 23:15:04.223194 16849 layer_factory.hpp:77] Creating layer fc2
I0819 23:15:04.223204 16849 net.cpp:91] Creating Layer fc2
I0819 23:15:04.223206 16849 net.cpp:425] fc2 <- fc1
I0819 23:15:04.223212 16849 net.cpp:399] fc2 -> fc2
I0819 23:15:04.564630 16849 net.cpp:141] Setting up fc2
I0819 23:15:04.564649 16849 net.cpp:148] Top shape: 500 4096 1 1 (2048000)
I0819 23:15:04.564654 16849 net.cpp:156] Memory required for data: 2187522000
I0819 23:15:04.564662 16849 layer_factory.hpp:77] Creating layer relu6
I0819 23:15:04.564671 16849 net.cpp:91] Creating Layer relu6
I0819 23:15:04.564678 16849 net.cpp:425] relu6 <- fc2
I0819 23:15:04.564684 16849 net.cpp:386] relu6 -> fc2 (in-place)
I0819 23:15:04.564877 16849 net.cpp:141] Setting up relu6
I0819 23:15:04.564885 16849 net.cpp:148] Top shape: 500 4096 1 1 (2048000)
I0819 23:15:04.564888 16849 net.cpp:156] Memory required for data: 2195714000
I0819 23:15:04.564890 16849 layer_factory.hpp:77] Creating layer fc_class
I0819 23:15:04.564898 16849 net.cpp:91] Creating Layer fc_class
I0819 23:15:04.564901 16849 net.cpp:425] fc_class <- fc2
I0819 23:15:04.564906 16849 net.cpp:399] fc_class -> fc_class
I0819 23:15:11.897661 16849 net.cpp:141] Setting up fc_class
I0819 23:15:11.897680 16849 net.cpp:148] Top shape: 500 88172 1 1 (44086000)
I0819 23:15:11.897685 16849 net.cpp:156] Memory required for data: 2372058000
I0819 23:15:11.897691 16849 layer_factory.hpp:77] Creating layer fc_class_fc_class_0_split
I0819 23:15:11.897697 16849 net.cpp:91] Creating Layer fc_class_fc_class_0_split
I0819 23:15:11.897701 16849 net.cpp:425] fc_class_fc_class_0_split <- fc_class
I0819 23:15:11.897706 16849 net.cpp:399] fc_class_fc_class_0_split -> fc_class_fc_class_0_split_0
I0819 23:15:11.897711 16849 net.cpp:399] fc_class_fc_class_0_split -> fc_class_fc_class_0_split_1
I0819 23:15:11.897739 16849 net.cpp:141] Setting up fc_class_fc_class_0_split
I0819 23:15:11.897744 16849 net.cpp:148] Top shape: 500 88172 1 1 (44086000)
I0819 23:15:11.897747 16849 net.cpp:148] Top shape: 500 88172 1 1 (44086000)
I0819 23:15:11.897750 16849 net.cpp:156] Memory required for data: 2724746000
I0819 23:15:11.897753 16849 layer_factory.hpp:77] Creating layer prob
I0819 23:15:11.897756 16849 net.cpp:91] Creating Layer prob
I0819 23:15:11.897758 16849 net.cpp:425] prob <- fc_class_fc_class_0_split_0
I0819 23:15:11.897761 16849 net.cpp:399] prob -> prob
I0819 23:15:11.897950 16849 net.cpp:141] Setting up prob
I0819 23:15:11.897958 16849 net.cpp:148] Top shape: 500 88172 1 1 (44086000)
I0819 23:15:11.897961 16849 net.cpp:156] Memory required for data: 2901090000
I0819 23:15:11.897964 16849 layer_factory.hpp:77] Creating layer loss
I0819 23:15:11.897967 16849 net.cpp:91] Creating Layer loss
I0819 23:15:11.897970 16849 net.cpp:425] loss <- fc_class_fc_class_0_split_1
I0819 23:15:11.897974 16849 net.cpp:425] loss <- label
I0819 23:15:11.897977 16849 net.cpp:399] loss -> loss
I0819 23:15:11.897985 16849 layer_factory.hpp:77] Creating layer loss
I0819 23:15:11.949344 16849 net.cpp:141] Setting up loss
I0819 23:15:11.949365 16849 net.cpp:148] Top shape: (1)
I0819 23:15:11.949368 16849 net.cpp:151]     with loss weight 1
I0819 23:15:11.949380 16849 net.cpp:156] Memory required for data: 2901090004
I0819 23:15:11.949383 16849 net.cpp:217] loss needs backward computation.
I0819 23:15:11.949388 16849 net.cpp:219] prob does not need backward computation.
I0819 23:15:11.949405 16849 net.cpp:217] fc_class_fc_class_0_split needs backward computation.
I0819 23:15:11.949407 16849 net.cpp:217] fc_class needs backward computation.
I0819 23:15:11.949410 16849 net.cpp:217] relu6 needs backward computation.
I0819 23:15:11.949412 16849 net.cpp:217] fc2 needs backward computation.
I0819 23:15:11.949415 16849 net.cpp:217] relu5 needs backward computation.
I0819 23:15:11.949419 16849 net.cpp:217] fc1 needs backward computation.
I0819 23:15:11.949422 16849 net.cpp:217] relu4 needs backward computation.
I0819 23:15:11.949424 16849 net.cpp:217] conv4 needs backward computation.
I0819 23:15:11.949426 16849 net.cpp:217] pool3 needs backward computation.
I0819 23:15:11.949429 16849 net.cpp:217] relu3_5 needs backward computation.
I0819 23:15:11.949431 16849 net.cpp:217] conv3_5 needs backward computation.
I0819 23:15:11.949434 16849 net.cpp:217] relu3 needs backward computation.
I0819 23:15:11.949436 16849 net.cpp:217] conv3 needs backward computation.
I0819 23:15:11.949440 16849 net.cpp:217] pool2 needs backward computation.
I0819 23:15:11.949443 16849 net.cpp:217] relu2 needs backward computation.
I0819 23:15:11.949445 16849 net.cpp:217] conv2 needs backward computation.
I0819 23:15:11.949448 16849 net.cpp:217] pool1 needs backward computation.
I0819 23:15:11.949450 16849 net.cpp:217] relu1 needs backward computation.
I0819 23:15:11.949452 16849 net.cpp:217] conv1 needs backward computation.
I0819 23:15:11.949455 16849 net.cpp:219] data does not need backward computation.
I0819 23:15:11.949457 16849 net.cpp:261] This network produces output loss
I0819 23:15:11.949461 16849 net.cpp:261] This network produces output prob
I0819 23:15:11.949472 16849 net.cpp:274] Network initialization done.
I0819 23:15:11.949934 16849 solver.cpp:181] Creating test net (#0) specified by net file: examples/jr-station/part_Dict.prototxt
I0819 23:15:11.949961 16849 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0819 23:15:11.950088 16849 net.cpp:49] Initializing net from parameters: 
name: "Bigram_Net_VGG"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
  }
  data_param {
    source: "examples/jr-station/img_part_test_lmdb"
    batch_size: 200
    backend: LMDB
  }
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 100
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3_5"
  type: "Convolution"
  bottom: "conv3"
  top: "conv3_5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_5"
  type: "ReLU"
  bottom: "conv3_5"
  top: "conv3_5"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_5"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "fc1"
  type: "Convolution"
  bottom: "conv4"
  top: "fc1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 4096
    pad: 0
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    kernel_h: 4
    kernel_w: 13
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "fc1"
  top: "fc1"
}
layer {
  name: "fc2"
  type: "Convolution"
  bottom: "fc1"
  top: "fc2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 4096
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc2"
  top: "fc2"
}
layer {
  name: "fc_class"
  type: "Convolution"
  bottom: "fc2"
  top: "fc_class"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 88172
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc_class"
  top: "prob"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc_class"
  bottom: "label"
  top: "loss"
}
I0819 23:15:11.950153 16849 layer_factory.hpp:77] Creating layer data
I0819 23:15:11.950270 16849 net.cpp:91] Creating Layer data
I0819 23:15:11.950278 16849 net.cpp:399] data -> data
I0819 23:15:11.950284 16849 net.cpp:399] data -> label
I0819 23:15:11.950839 16876 db_lmdb.cpp:35] Opened lmdb examples/jr-station/img_part_test_lmdb
I0819 23:15:11.950961 16849 data_layer.cpp:41] output data size: 200,1,32,100
I0819 23:15:11.954170 16849 net.cpp:141] Setting up data
I0819 23:15:11.954190 16849 net.cpp:148] Top shape: 200 1 32 100 (640000)
I0819 23:15:11.954193 16849 net.cpp:148] Top shape: 200 (200)
I0819 23:15:11.954195 16849 net.cpp:156] Memory required for data: 2560800
I0819 23:15:11.954200 16849 layer_factory.hpp:77] Creating layer conv1
I0819 23:15:11.954212 16849 net.cpp:91] Creating Layer conv1
I0819 23:15:11.954216 16849 net.cpp:425] conv1 <- data
I0819 23:15:11.954221 16849 net.cpp:399] conv1 -> conv1
I0819 23:15:11.955457 16849 net.cpp:141] Setting up conv1
I0819 23:15:11.955468 16849 net.cpp:148] Top shape: 200 64 32 100 (40960000)
I0819 23:15:11.955471 16849 net.cpp:156] Memory required for data: 166400800
I0819 23:15:11.955479 16849 layer_factory.hpp:77] Creating layer relu1
I0819 23:15:11.955487 16849 net.cpp:91] Creating Layer relu1
I0819 23:15:11.955489 16849 net.cpp:425] relu1 <- conv1
I0819 23:15:11.955492 16849 net.cpp:386] relu1 -> conv1 (in-place)
I0819 23:15:11.955700 16849 net.cpp:141] Setting up relu1
I0819 23:15:11.955709 16849 net.cpp:148] Top shape: 200 64 32 100 (40960000)
I0819 23:15:11.955713 16849 net.cpp:156] Memory required for data: 330240800
I0819 23:15:11.955714 16849 layer_factory.hpp:77] Creating layer pool1
I0819 23:15:11.955720 16849 net.cpp:91] Creating Layer pool1
I0819 23:15:11.955724 16849 net.cpp:425] pool1 <- conv1
I0819 23:15:11.955726 16849 net.cpp:399] pool1 -> pool1
I0819 23:15:11.955759 16849 net.cpp:141] Setting up pool1
I0819 23:15:11.955763 16849 net.cpp:148] Top shape: 200 64 16 50 (10240000)
I0819 23:15:11.955766 16849 net.cpp:156] Memory required for data: 371200800
I0819 23:15:11.955770 16849 layer_factory.hpp:77] Creating layer conv2
I0819 23:15:11.955783 16849 net.cpp:91] Creating Layer conv2
I0819 23:15:11.955786 16849 net.cpp:425] conv2 <- pool1
I0819 23:15:11.955793 16849 net.cpp:399] conv2 -> conv2
I0819 23:15:11.961346 16849 net.cpp:141] Setting up conv2
I0819 23:15:11.961364 16849 net.cpp:148] Top shape: 200 128 16 50 (20480000)
I0819 23:15:11.961367 16849 net.cpp:156] Memory required for data: 453120800
I0819 23:15:11.961375 16849 layer_factory.hpp:77] Creating layer relu2
I0819 23:15:11.961382 16849 net.cpp:91] Creating Layer relu2
I0819 23:15:11.961386 16849 net.cpp:425] relu2 <- conv2
I0819 23:15:11.961391 16849 net.cpp:386] relu2 -> conv2 (in-place)
I0819 23:15:11.961506 16849 net.cpp:141] Setting up relu2
I0819 23:15:11.961513 16849 net.cpp:148] Top shape: 200 128 16 50 (20480000)
I0819 23:15:11.961516 16849 net.cpp:156] Memory required for data: 535040800
I0819 23:15:11.961519 16849 layer_factory.hpp:77] Creating layer pool2
I0819 23:15:11.961524 16849 net.cpp:91] Creating Layer pool2
I0819 23:15:11.961527 16849 net.cpp:425] pool2 <- conv2
I0819 23:15:11.961531 16849 net.cpp:399] pool2 -> pool2
I0819 23:15:11.961560 16849 net.cpp:141] Setting up pool2
I0819 23:15:11.961566 16849 net.cpp:148] Top shape: 200 128 8 25 (5120000)
I0819 23:15:11.961568 16849 net.cpp:156] Memory required for data: 555520800
I0819 23:15:11.961571 16849 layer_factory.hpp:77] Creating layer conv3
I0819 23:15:11.961578 16849 net.cpp:91] Creating Layer conv3
I0819 23:15:11.961581 16849 net.cpp:425] conv3 <- pool2
I0819 23:15:11.961586 16849 net.cpp:399] conv3 -> conv3
I0819 23:15:11.968322 16849 net.cpp:141] Setting up conv3
I0819 23:15:11.968333 16849 net.cpp:148] Top shape: 200 256 8 25 (10240000)
I0819 23:15:11.968335 16849 net.cpp:156] Memory required for data: 596480800
I0819 23:15:11.968341 16849 layer_factory.hpp:77] Creating layer relu3
I0819 23:15:11.968349 16849 net.cpp:91] Creating Layer relu3
I0819 23:15:11.968353 16849 net.cpp:425] relu3 <- conv3
I0819 23:15:11.968356 16849 net.cpp:386] relu3 -> conv3 (in-place)
I0819 23:15:11.968549 16849 net.cpp:141] Setting up relu3
I0819 23:15:11.968557 16849 net.cpp:148] Top shape: 200 256 8 25 (10240000)
I0819 23:15:11.968561 16849 net.cpp:156] Memory required for data: 637440800
I0819 23:15:11.968564 16849 layer_factory.hpp:77] Creating layer conv3_5
I0819 23:15:11.968571 16849 net.cpp:91] Creating Layer conv3_5
I0819 23:15:11.968575 16849 net.cpp:425] conv3_5 <- conv3
I0819 23:15:11.968580 16849 net.cpp:399] conv3_5 -> conv3_5
I0819 23:15:11.993340 16849 net.cpp:141] Setting up conv3_5
I0819 23:15:11.993360 16849 net.cpp:148] Top shape: 200 512 8 25 (20480000)
I0819 23:15:11.993362 16849 net.cpp:156] Memory required for data: 719360800
I0819 23:15:11.993368 16849 layer_factory.hpp:77] Creating layer relu3_5
I0819 23:15:11.993376 16849 net.cpp:91] Creating Layer relu3_5
I0819 23:15:11.993379 16849 net.cpp:425] relu3_5 <- conv3_5
I0819 23:15:11.993383 16849 net.cpp:386] relu3_5 -> conv3_5 (in-place)
I0819 23:15:11.993566 16849 net.cpp:141] Setting up relu3_5
I0819 23:15:11.993574 16849 net.cpp:148] Top shape: 200 512 8 25 (20480000)
I0819 23:15:11.993577 16849 net.cpp:156] Memory required for data: 801280800
I0819 23:15:11.993579 16849 layer_factory.hpp:77] Creating layer pool3
I0819 23:15:11.993584 16849 net.cpp:91] Creating Layer pool3
I0819 23:15:11.993597 16849 net.cpp:425] pool3 <- conv3_5
I0819 23:15:11.993600 16849 net.cpp:399] pool3 -> pool3
I0819 23:15:11.993634 16849 net.cpp:141] Setting up pool3
I0819 23:15:11.993640 16849 net.cpp:148] Top shape: 200 512 4 13 (5324800)
I0819 23:15:11.993643 16849 net.cpp:156] Memory required for data: 822580000
I0819 23:15:11.993644 16849 layer_factory.hpp:77] Creating layer conv4
I0819 23:15:11.993652 16849 net.cpp:91] Creating Layer conv4
I0819 23:15:11.993654 16849 net.cpp:425] conv4 <- pool3
I0819 23:15:11.993659 16849 net.cpp:399] conv4 -> conv4
I0819 23:15:12.042073 16849 net.cpp:141] Setting up conv4
I0819 23:15:12.042093 16849 net.cpp:148] Top shape: 200 512 4 13 (5324800)
I0819 23:15:12.042095 16849 net.cpp:156] Memory required for data: 843879200
I0819 23:15:12.042105 16849 layer_factory.hpp:77] Creating layer relu4
I0819 23:15:12.042112 16849 net.cpp:91] Creating Layer relu4
I0819 23:15:12.042115 16849 net.cpp:425] relu4 <- conv4
I0819 23:15:12.042119 16849 net.cpp:386] relu4 -> conv4 (in-place)
I0819 23:15:12.042232 16849 net.cpp:141] Setting up relu4
I0819 23:15:12.042238 16849 net.cpp:148] Top shape: 200 512 4 13 (5324800)
I0819 23:15:12.042240 16849 net.cpp:156] Memory required for data: 865178400
I0819 23:15:12.042243 16849 layer_factory.hpp:77] Creating layer fc1
I0819 23:15:12.042250 16849 net.cpp:91] Creating Layer fc1
I0819 23:15:12.042254 16849 net.cpp:425] fc1 <- conv4
I0819 23:15:12.042258 16849 net.cpp:399] fc1 -> fc1
I0819 23:15:14.252946 16849 net.cpp:141] Setting up fc1
I0819 23:15:14.252964 16849 net.cpp:148] Top shape: 200 4096 1 1 (819200)
I0819 23:15:14.252967 16849 net.cpp:156] Memory required for data: 868455200
I0819 23:15:14.252974 16849 layer_factory.hpp:77] Creating layer relu5
I0819 23:15:14.252980 16849 net.cpp:91] Creating Layer relu5
I0819 23:15:14.252984 16849 net.cpp:425] relu5 <- fc1
I0819 23:15:14.252988 16849 net.cpp:386] relu5 -> fc1 (in-place)
I0819 23:15:14.253177 16849 net.cpp:141] Setting up relu5
I0819 23:15:14.253185 16849 net.cpp:148] Top shape: 200 4096 1 1 (819200)
I0819 23:15:14.253188 16849 net.cpp:156] Memory required for data: 871732000
I0819 23:15:14.253190 16849 layer_factory.hpp:77] Creating layer fc2
I0819 23:15:14.253201 16849 net.cpp:91] Creating Layer fc2
I0819 23:15:14.253203 16849 net.cpp:425] fc2 <- fc1
I0819 23:15:14.253208 16849 net.cpp:399] fc2 -> fc2
I0819 23:15:14.594800 16849 net.cpp:141] Setting up fc2
I0819 23:15:14.594817 16849 net.cpp:148] Top shape: 200 4096 1 1 (819200)
I0819 23:15:14.594821 16849 net.cpp:156] Memory required for data: 875008800
I0819 23:15:14.594828 16849 layer_factory.hpp:77] Creating layer relu6
I0819 23:15:14.594836 16849 net.cpp:91] Creating Layer relu6
I0819 23:15:14.594840 16849 net.cpp:425] relu6 <- fc2
I0819 23:15:14.594844 16849 net.cpp:386] relu6 -> fc2 (in-place)
I0819 23:15:14.595031 16849 net.cpp:141] Setting up relu6
I0819 23:15:14.595038 16849 net.cpp:148] Top shape: 200 4096 1 1 (819200)
I0819 23:15:14.595041 16849 net.cpp:156] Memory required for data: 878285600
I0819 23:15:14.595043 16849 layer_factory.hpp:77] Creating layer fc_class
I0819 23:15:14.595052 16849 net.cpp:91] Creating Layer fc_class
I0819 23:15:14.595054 16849 net.cpp:425] fc_class <- fc2
I0819 23:15:14.595059 16849 net.cpp:399] fc_class -> fc_class
I0819 23:15:21.919845 16849 net.cpp:141] Setting up fc_class
I0819 23:15:21.919867 16849 net.cpp:148] Top shape: 200 88172 1 1 (17634400)
I0819 23:15:21.919870 16849 net.cpp:156] Memory required for data: 948823200
I0819 23:15:21.919878 16849 layer_factory.hpp:77] Creating layer fc_class_fc_class_0_split
I0819 23:15:21.919883 16849 net.cpp:91] Creating Layer fc_class_fc_class_0_split
I0819 23:15:21.919886 16849 net.cpp:425] fc_class_fc_class_0_split <- fc_class
I0819 23:15:21.919890 16849 net.cpp:399] fc_class_fc_class_0_split -> fc_class_fc_class_0_split_0
I0819 23:15:21.919898 16849 net.cpp:399] fc_class_fc_class_0_split -> fc_class_fc_class_0_split_1
I0819 23:15:21.919929 16849 net.cpp:141] Setting up fc_class_fc_class_0_split
I0819 23:15:21.919934 16849 net.cpp:148] Top shape: 200 88172 1 1 (17634400)
I0819 23:15:21.919947 16849 net.cpp:148] Top shape: 200 88172 1 1 (17634400)
I0819 23:15:21.919950 16849 net.cpp:156] Memory required for data: 1089898400
I0819 23:15:21.919952 16849 layer_factory.hpp:77] Creating layer prob
I0819 23:15:21.919956 16849 net.cpp:91] Creating Layer prob
I0819 23:15:21.919958 16849 net.cpp:425] prob <- fc_class_fc_class_0_split_0
I0819 23:15:21.919962 16849 net.cpp:399] prob -> prob
I0819 23:15:21.920390 16849 net.cpp:141] Setting up prob
I0819 23:15:21.920398 16849 net.cpp:148] Top shape: 200 88172 1 1 (17634400)
I0819 23:15:21.920402 16849 net.cpp:156] Memory required for data: 1160436000
I0819 23:15:21.920404 16849 layer_factory.hpp:77] Creating layer loss
I0819 23:15:21.920408 16849 net.cpp:91] Creating Layer loss
I0819 23:15:21.920410 16849 net.cpp:425] loss <- fc_class_fc_class_0_split_1
I0819 23:15:21.920413 16849 net.cpp:425] loss <- label
I0819 23:15:21.920418 16849 net.cpp:399] loss -> loss
I0819 23:15:21.920425 16849 layer_factory.hpp:77] Creating layer loss
I0819 23:15:21.941222 16849 net.cpp:141] Setting up loss
I0819 23:15:21.941241 16849 net.cpp:148] Top shape: (1)
I0819 23:15:21.941244 16849 net.cpp:151]     with loss weight 1
I0819 23:15:21.941251 16849 net.cpp:156] Memory required for data: 1160436004
I0819 23:15:21.941256 16849 net.cpp:217] loss needs backward computation.
I0819 23:15:21.941258 16849 net.cpp:219] prob does not need backward computation.
I0819 23:15:21.941262 16849 net.cpp:217] fc_class_fc_class_0_split needs backward computation.
I0819 23:15:21.941263 16849 net.cpp:217] fc_class needs backward computation.
I0819 23:15:21.941267 16849 net.cpp:217] relu6 needs backward computation.
I0819 23:15:21.941268 16849 net.cpp:217] fc2 needs backward computation.
I0819 23:15:21.941272 16849 net.cpp:217] relu5 needs backward computation.
I0819 23:15:21.941273 16849 net.cpp:217] fc1 needs backward computation.
I0819 23:15:21.941275 16849 net.cpp:217] relu4 needs backward computation.
I0819 23:15:21.941278 16849 net.cpp:217] conv4 needs backward computation.
I0819 23:15:21.941280 16849 net.cpp:217] pool3 needs backward computation.
I0819 23:15:21.941282 16849 net.cpp:217] relu3_5 needs backward computation.
I0819 23:15:21.941285 16849 net.cpp:217] conv3_5 needs backward computation.
I0819 23:15:21.941287 16849 net.cpp:217] relu3 needs backward computation.
I0819 23:15:21.941290 16849 net.cpp:217] conv3 needs backward computation.
I0819 23:15:21.941293 16849 net.cpp:217] pool2 needs backward computation.
I0819 23:15:21.941296 16849 net.cpp:217] relu2 needs backward computation.
I0819 23:15:21.941299 16849 net.cpp:217] conv2 needs backward computation.
I0819 23:15:21.941301 16849 net.cpp:217] pool1 needs backward computation.
I0819 23:15:21.941304 16849 net.cpp:217] relu1 needs backward computation.
I0819 23:15:21.941306 16849 net.cpp:217] conv1 needs backward computation.
I0819 23:15:21.941308 16849 net.cpp:219] data does not need backward computation.
I0819 23:15:21.941310 16849 net.cpp:261] This network produces output loss
I0819 23:15:21.941314 16849 net.cpp:261] This network produces output prob
I0819 23:15:21.941324 16849 net.cpp:274] Network initialization done.
I0819 23:15:21.941386 16849 solver.cpp:60] Solver scaffolding done.
I0819 23:15:21.941807 16849 caffe.cpp:129] Finetuning from examples/jr-station/pre.caffemodel
F0819 23:15:21.941828 16849 io.cpp:54] Check failed: fd != -1 (-1 vs. -1) File not found: examples/jr-station/pre.caffemodel
*** Check failure stack trace: ***
    @     0x7f281d436daa  (unknown)
    @     0x7f281d436ce4  (unknown)
    @     0x7f281d4366e6  (unknown)
    @     0x7f281d439687  (unknown)
    @     0x7f281dbb8d5f  caffe::ReadProtoFromBinaryFile()
    @     0x7f281dbc0bd4  caffe::ReadNetParamsFromBinaryFileOrDie()
    @     0x7f281da63ca7  caffe::Net<>::CopyTrainedLayersFromBinaryProto()
    @     0x7f281da63d16  caffe::Net<>::CopyTrainedLayersFrom()
    @           0x407794  CopyLayers()
    @           0x407f95  train()
    @           0x4059bc  main
    @     0x7f281c744f45  (unknown)
    @           0x4060f1  (unknown)
    @              (nil)  (unknown)
