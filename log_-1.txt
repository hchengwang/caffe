I0822 19:51:41.320137 14094 caffe.cpp:185] Using GPUs 0
I0822 19:51:41.359792 14094 caffe.cpp:190] GPU 0: GeForce GTX TITAN X
I0822 19:51:41.484233 14094 solver.cpp:48] Initializing solver from parameters: 
test_iter: 750
test_interval: 1000
base_lr: 0.001
display: 50
max_iter: 8000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 2000
snapshot: 4000
snapshot_prefix: "examples/jr-station/vgg"
solver_mode: GPU
device_id: 0
net: "examples/jr-station/part_Dict.prototxt"
I0822 19:51:41.484324 14094 solver.cpp:91] Creating training net from net file: examples/jr-station/part_Dict.prototxt
I0822 19:51:41.484791 14094 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0822 19:51:41.484927 14094 net.cpp:49] Initializing net from parameters: 
name: "Bigram_Net_VGG"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
  }
  data_param {
    source: "examples/jr-station/img_part_train_lmdb"
    batch_size: 500
    backend: LMDB
  }
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 100
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3_5"
  type: "Convolution"
  bottom: "conv3"
  top: "conv3_5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_5"
  type: "ReLU"
  bottom: "conv3_5"
  top: "conv3_5"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_5"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "fc1"
  type: "Convolution"
  bottom: "conv4"
  top: "fc1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 4096
    pad: 0
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    kernel_h: 4
    kernel_w: 13
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "fc1"
  top: "fc1"
}
layer {
  name: "fc2"
  type: "Convolution"
  bottom: "fc1"
  top: "fc2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 4096
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc2"
  top: "fc2"
}
layer {
  name: "fc_class"
  type: "Convolution"
  bottom: "fc2"
  top: "fc_class"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 88172
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc_class"
  top: "prob"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc_class"
  bottom: "label"
  top: "loss"
}
I0822 19:51:41.485010 14094 layer_factory.hpp:77] Creating layer data
I0822 19:51:41.485515 14094 net.cpp:91] Creating Layer data
I0822 19:51:41.485523 14094 net.cpp:399] data -> data
I0822 19:51:41.485540 14094 net.cpp:399] data -> label
I0822 19:51:41.486053 14100 db_lmdb.cpp:35] Opened lmdb examples/jr-station/img_part_train_lmdb
I0822 19:51:41.492794 14094 data_layer.cpp:41] output data size: 500,1,32,100
I0822 19:51:41.500532 14094 net.cpp:141] Setting up data
I0822 19:51:41.500555 14094 net.cpp:148] Top shape: 500 1 32 100 (1600000)
I0822 19:51:41.500560 14094 net.cpp:148] Top shape: 500 (500)
I0822 19:51:41.500562 14094 net.cpp:156] Memory required for data: 6402000
I0822 19:51:41.500568 14094 layer_factory.hpp:77] Creating layer conv1
I0822 19:51:41.500593 14094 net.cpp:91] Creating Layer conv1
I0822 19:51:41.500599 14094 net.cpp:425] conv1 <- data
I0822 19:51:41.500609 14094 net.cpp:399] conv1 -> conv1
I0822 19:51:41.621623 14094 net.cpp:141] Setting up conv1
I0822 19:51:41.621644 14094 net.cpp:148] Top shape: 500 64 32 100 (102400000)
I0822 19:51:41.621649 14094 net.cpp:156] Memory required for data: 416002000
I0822 19:51:41.621659 14094 layer_factory.hpp:77] Creating layer relu1
I0822 19:51:41.621666 14094 net.cpp:91] Creating Layer relu1
I0822 19:51:41.621670 14094 net.cpp:425] relu1 <- conv1
I0822 19:51:41.621675 14094 net.cpp:386] relu1 -> conv1 (in-place)
I0822 19:51:41.621865 14094 net.cpp:141] Setting up relu1
I0822 19:51:41.621875 14094 net.cpp:148] Top shape: 500 64 32 100 (102400000)
I0822 19:51:41.621876 14094 net.cpp:156] Memory required for data: 825602000
I0822 19:51:41.621879 14094 layer_factory.hpp:77] Creating layer pool1
I0822 19:51:41.621884 14094 net.cpp:91] Creating Layer pool1
I0822 19:51:41.621886 14094 net.cpp:425] pool1 <- conv1
I0822 19:51:41.621891 14094 net.cpp:399] pool1 -> pool1
I0822 19:51:41.621923 14094 net.cpp:141] Setting up pool1
I0822 19:51:41.621928 14094 net.cpp:148] Top shape: 500 64 16 50 (25600000)
I0822 19:51:41.621930 14094 net.cpp:156] Memory required for data: 928002000
I0822 19:51:41.621933 14094 layer_factory.hpp:77] Creating layer conv2
I0822 19:51:41.621942 14094 net.cpp:91] Creating Layer conv2
I0822 19:51:41.621944 14094 net.cpp:425] conv2 <- pool1
I0822 19:51:41.621948 14094 net.cpp:399] conv2 -> conv2
I0822 19:51:41.626768 14094 net.cpp:141] Setting up conv2
I0822 19:51:41.626778 14094 net.cpp:148] Top shape: 500 128 16 50 (51200000)
I0822 19:51:41.626781 14094 net.cpp:156] Memory required for data: 1132802000
I0822 19:51:41.626787 14094 layer_factory.hpp:77] Creating layer relu2
I0822 19:51:41.626791 14094 net.cpp:91] Creating Layer relu2
I0822 19:51:41.626794 14094 net.cpp:425] relu2 <- conv2
I0822 19:51:41.626797 14094 net.cpp:386] relu2 -> conv2 (in-place)
I0822 19:51:41.626907 14094 net.cpp:141] Setting up relu2
I0822 19:51:41.626914 14094 net.cpp:148] Top shape: 500 128 16 50 (51200000)
I0822 19:51:41.626916 14094 net.cpp:156] Memory required for data: 1337602000
I0822 19:51:41.626919 14094 layer_factory.hpp:77] Creating layer pool2
I0822 19:51:41.626924 14094 net.cpp:91] Creating Layer pool2
I0822 19:51:41.626925 14094 net.cpp:425] pool2 <- conv2
I0822 19:51:41.626929 14094 net.cpp:399] pool2 -> pool2
I0822 19:51:41.626952 14094 net.cpp:141] Setting up pool2
I0822 19:51:41.626957 14094 net.cpp:148] Top shape: 500 128 8 25 (12800000)
I0822 19:51:41.626960 14094 net.cpp:156] Memory required for data: 1388802000
I0822 19:51:41.626961 14094 layer_factory.hpp:77] Creating layer conv3
I0822 19:51:41.626967 14094 net.cpp:91] Creating Layer conv3
I0822 19:51:41.626971 14094 net.cpp:425] conv3 <- pool2
I0822 19:51:41.626974 14094 net.cpp:399] conv3 -> conv3
I0822 19:51:41.633733 14094 net.cpp:141] Setting up conv3
I0822 19:51:41.633745 14094 net.cpp:148] Top shape: 500 256 8 25 (25600000)
I0822 19:51:41.633749 14094 net.cpp:156] Memory required for data: 1491202000
I0822 19:51:41.633756 14094 layer_factory.hpp:77] Creating layer relu3
I0822 19:51:41.633762 14094 net.cpp:91] Creating Layer relu3
I0822 19:51:41.633764 14094 net.cpp:425] relu3 <- conv3
I0822 19:51:41.633769 14094 net.cpp:386] relu3 -> conv3 (in-place)
I0822 19:51:41.633877 14094 net.cpp:141] Setting up relu3
I0822 19:51:41.633883 14094 net.cpp:148] Top shape: 500 256 8 25 (25600000)
I0822 19:51:41.633887 14094 net.cpp:156] Memory required for data: 1593602000
I0822 19:51:41.633888 14094 layer_factory.hpp:77] Creating layer conv3_5
I0822 19:51:41.633895 14094 net.cpp:91] Creating Layer conv3_5
I0822 19:51:41.633898 14094 net.cpp:425] conv3_5 <- conv3
I0822 19:51:41.633903 14094 net.cpp:399] conv3_5 -> conv3_5
I0822 19:51:41.658756 14094 net.cpp:141] Setting up conv3_5
I0822 19:51:41.658776 14094 net.cpp:148] Top shape: 500 512 8 25 (51200000)
I0822 19:51:41.658778 14094 net.cpp:156] Memory required for data: 1798402000
I0822 19:51:41.658784 14094 layer_factory.hpp:77] Creating layer relu3_5
I0822 19:51:41.658790 14094 net.cpp:91] Creating Layer relu3_5
I0822 19:51:41.658793 14094 net.cpp:425] relu3_5 <- conv3_5
I0822 19:51:41.658797 14094 net.cpp:386] relu3_5 -> conv3_5 (in-place)
I0822 19:51:41.658982 14094 net.cpp:141] Setting up relu3_5
I0822 19:51:41.658989 14094 net.cpp:148] Top shape: 500 512 8 25 (51200000)
I0822 19:51:41.658993 14094 net.cpp:156] Memory required for data: 2003202000
I0822 19:51:41.658994 14094 layer_factory.hpp:77] Creating layer pool3
I0822 19:51:41.658999 14094 net.cpp:91] Creating Layer pool3
I0822 19:51:41.659001 14094 net.cpp:425] pool3 <- conv3_5
I0822 19:51:41.659005 14094 net.cpp:399] pool3 -> pool3
I0822 19:51:41.659036 14094 net.cpp:141] Setting up pool3
I0822 19:51:41.659041 14094 net.cpp:148] Top shape: 500 512 4 13 (13312000)
I0822 19:51:41.659044 14094 net.cpp:156] Memory required for data: 2056450000
I0822 19:51:41.659045 14094 layer_factory.hpp:77] Creating layer conv4
I0822 19:51:41.659054 14094 net.cpp:91] Creating Layer conv4
I0822 19:51:41.659056 14094 net.cpp:425] conv4 <- pool3
I0822 19:51:41.659060 14094 net.cpp:399] conv4 -> conv4
I0822 19:51:41.707420 14094 net.cpp:141] Setting up conv4
I0822 19:51:41.707438 14094 net.cpp:148] Top shape: 500 512 4 13 (13312000)
I0822 19:51:41.707442 14094 net.cpp:156] Memory required for data: 2109698000
I0822 19:51:41.707450 14094 layer_factory.hpp:77] Creating layer relu4
I0822 19:51:41.707456 14094 net.cpp:91] Creating Layer relu4
I0822 19:51:41.707459 14094 net.cpp:425] relu4 <- conv4
I0822 19:51:41.707463 14094 net.cpp:386] relu4 -> conv4 (in-place)
I0822 19:51:41.707573 14094 net.cpp:141] Setting up relu4
I0822 19:51:41.707581 14094 net.cpp:148] Top shape: 500 512 4 13 (13312000)
I0822 19:51:41.707583 14094 net.cpp:156] Memory required for data: 2162946000
I0822 19:51:41.707586 14094 layer_factory.hpp:77] Creating layer fc1
I0822 19:51:41.707593 14094 net.cpp:91] Creating Layer fc1
I0822 19:51:41.707595 14094 net.cpp:425] fc1 <- conv4
I0822 19:51:41.707610 14094 net.cpp:399] fc1 -> fc1
I0822 19:51:43.914322 14094 net.cpp:141] Setting up fc1
I0822 19:51:43.914343 14094 net.cpp:148] Top shape: 500 4096 1 1 (2048000)
I0822 19:51:43.914346 14094 net.cpp:156] Memory required for data: 2171138000
I0822 19:51:43.914352 14094 layer_factory.hpp:77] Creating layer relu5
I0822 19:51:43.914360 14094 net.cpp:91] Creating Layer relu5
I0822 19:51:43.914362 14094 net.cpp:425] relu5 <- fc1
I0822 19:51:43.914366 14094 net.cpp:386] relu5 -> fc1 (in-place)
I0822 19:51:43.914489 14094 net.cpp:141] Setting up relu5
I0822 19:51:43.914496 14094 net.cpp:148] Top shape: 500 4096 1 1 (2048000)
I0822 19:51:43.914499 14094 net.cpp:156] Memory required for data: 2179330000
I0822 19:51:43.914501 14094 layer_factory.hpp:77] Creating layer fc2
I0822 19:51:43.914511 14094 net.cpp:91] Creating Layer fc2
I0822 19:51:43.914515 14094 net.cpp:425] fc2 <- fc1
I0822 19:51:43.914520 14094 net.cpp:399] fc2 -> fc2
I0822 19:51:44.254958 14094 net.cpp:141] Setting up fc2
I0822 19:51:44.254976 14094 net.cpp:148] Top shape: 500 4096 1 1 (2048000)
I0822 19:51:44.254979 14094 net.cpp:156] Memory required for data: 2187522000
I0822 19:51:44.254984 14094 layer_factory.hpp:77] Creating layer relu6
I0822 19:51:44.254992 14094 net.cpp:91] Creating Layer relu6
I0822 19:51:44.254994 14094 net.cpp:425] relu6 <- fc2
I0822 19:51:44.254999 14094 net.cpp:386] relu6 -> fc2 (in-place)
I0822 19:51:44.255195 14094 net.cpp:141] Setting up relu6
I0822 19:51:44.255203 14094 net.cpp:148] Top shape: 500 4096 1 1 (2048000)
I0822 19:51:44.255206 14094 net.cpp:156] Memory required for data: 2195714000
I0822 19:51:44.255208 14094 layer_factory.hpp:77] Creating layer fc_class
I0822 19:51:44.255216 14094 net.cpp:91] Creating Layer fc_class
I0822 19:51:44.255219 14094 net.cpp:425] fc_class <- fc2
I0822 19:51:44.255224 14094 net.cpp:399] fc_class -> fc_class
I0822 19:51:51.555145 14094 net.cpp:141] Setting up fc_class
I0822 19:51:51.555166 14094 net.cpp:148] Top shape: 500 88172 1 1 (44086000)
I0822 19:51:51.555168 14094 net.cpp:156] Memory required for data: 2372058000
I0822 19:51:51.555174 14094 layer_factory.hpp:77] Creating layer fc_class_fc_class_0_split
I0822 19:51:51.555181 14094 net.cpp:91] Creating Layer fc_class_fc_class_0_split
I0822 19:51:51.555184 14094 net.cpp:425] fc_class_fc_class_0_split <- fc_class
I0822 19:51:51.555189 14094 net.cpp:399] fc_class_fc_class_0_split -> fc_class_fc_class_0_split_0
I0822 19:51:51.555197 14094 net.cpp:399] fc_class_fc_class_0_split -> fc_class_fc_class_0_split_1
I0822 19:51:51.555228 14094 net.cpp:141] Setting up fc_class_fc_class_0_split
I0822 19:51:51.555236 14094 net.cpp:148] Top shape: 500 88172 1 1 (44086000)
I0822 19:51:51.555239 14094 net.cpp:148] Top shape: 500 88172 1 1 (44086000)
I0822 19:51:51.555241 14094 net.cpp:156] Memory required for data: 2724746000
I0822 19:51:51.555243 14094 layer_factory.hpp:77] Creating layer prob
I0822 19:51:51.555248 14094 net.cpp:91] Creating Layer prob
I0822 19:51:51.555250 14094 net.cpp:425] prob <- fc_class_fc_class_0_split_0
I0822 19:51:51.555253 14094 net.cpp:399] prob -> prob
I0822 19:51:51.555440 14094 net.cpp:141] Setting up prob
I0822 19:51:51.555446 14094 net.cpp:148] Top shape: 500 88172 1 1 (44086000)
I0822 19:51:51.555449 14094 net.cpp:156] Memory required for data: 2901090000
I0822 19:51:51.555451 14094 layer_factory.hpp:77] Creating layer loss
I0822 19:51:51.555461 14094 net.cpp:91] Creating Layer loss
I0822 19:51:51.555464 14094 net.cpp:425] loss <- fc_class_fc_class_0_split_1
I0822 19:51:51.555466 14094 net.cpp:425] loss <- label
I0822 19:51:51.555470 14094 net.cpp:399] loss -> loss
I0822 19:51:51.555480 14094 layer_factory.hpp:77] Creating layer loss
I0822 19:51:51.603960 14094 net.cpp:141] Setting up loss
I0822 19:51:51.603979 14094 net.cpp:148] Top shape: (1)
I0822 19:51:51.603982 14094 net.cpp:151]     with loss weight 1
I0822 19:51:51.603994 14094 net.cpp:156] Memory required for data: 2901090004
I0822 19:51:51.603998 14094 net.cpp:217] loss needs backward computation.
I0822 19:51:51.604002 14094 net.cpp:219] prob does not need backward computation.
I0822 19:51:51.604019 14094 net.cpp:217] fc_class_fc_class_0_split needs backward computation.
I0822 19:51:51.604022 14094 net.cpp:217] fc_class needs backward computation.
I0822 19:51:51.604024 14094 net.cpp:217] relu6 needs backward computation.
I0822 19:51:51.604027 14094 net.cpp:217] fc2 needs backward computation.
I0822 19:51:51.604030 14094 net.cpp:217] relu5 needs backward computation.
I0822 19:51:51.604038 14094 net.cpp:217] fc1 needs backward computation.
I0822 19:51:51.604041 14094 net.cpp:217] relu4 needs backward computation.
I0822 19:51:51.604044 14094 net.cpp:217] conv4 needs backward computation.
I0822 19:51:51.604048 14094 net.cpp:217] pool3 needs backward computation.
I0822 19:51:51.604051 14094 net.cpp:217] relu3_5 needs backward computation.
I0822 19:51:51.604053 14094 net.cpp:217] conv3_5 needs backward computation.
I0822 19:51:51.604055 14094 net.cpp:217] relu3 needs backward computation.
I0822 19:51:51.604058 14094 net.cpp:217] conv3 needs backward computation.
I0822 19:51:51.604060 14094 net.cpp:217] pool2 needs backward computation.
I0822 19:51:51.604063 14094 net.cpp:217] relu2 needs backward computation.
I0822 19:51:51.604064 14094 net.cpp:217] conv2 needs backward computation.
I0822 19:51:51.604068 14094 net.cpp:217] pool1 needs backward computation.
I0822 19:51:51.604069 14094 net.cpp:217] relu1 needs backward computation.
I0822 19:51:51.604071 14094 net.cpp:217] conv1 needs backward computation.
I0822 19:51:51.604074 14094 net.cpp:219] data does not need backward computation.
I0822 19:51:51.604076 14094 net.cpp:261] This network produces output loss
I0822 19:51:51.604079 14094 net.cpp:261] This network produces output prob
I0822 19:51:51.604091 14094 net.cpp:274] Network initialization done.
I0822 19:51:51.604549 14094 solver.cpp:181] Creating test net (#0) specified by net file: examples/jr-station/part_Dict.prototxt
I0822 19:51:51.604576 14094 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0822 19:51:51.604704 14094 net.cpp:49] Initializing net from parameters: 
name: "Bigram_Net_VGG"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
  }
  data_param {
    source: "examples/jr-station/img_part_test_lmdb"
    batch_size: 200
    backend: LMDB
  }
  input_param {
    shape {
      dim: 1
      dim: 1
      dim: 32
      dim: 100
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "conv3"
  top: "conv3"
}
layer {
  name: "conv3_5"
  type: "Convolution"
  bottom: "conv3"
  top: "conv3_5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_5"
  type: "ReLU"
  bottom: "conv3_5"
  top: "conv3_5"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_5"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "conv4"
  top: "conv4"
}
layer {
  name: "fc1"
  type: "Convolution"
  bottom: "conv4"
  top: "fc1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 4096
    pad: 0
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
    kernel_h: 4
    kernel_w: 13
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "fc1"
  top: "fc1"
}
layer {
  name: "fc2"
  type: "Convolution"
  bottom: "fc1"
  top: "fc2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 4096
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "fc2"
  top: "fc2"
}
layer {
  name: "fc_class"
  type: "Convolution"
  bottom: "fc2"
  top: "fc_class"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 88172
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "prob"
  type: "Softmax"
  bottom: "fc_class"
  top: "prob"
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc_class"
  bottom: "label"
  top: "loss"
}
I0822 19:51:51.604768 14094 layer_factory.hpp:77] Creating layer data
I0822 19:51:51.604882 14094 net.cpp:91] Creating Layer data
I0822 19:51:51.604888 14094 net.cpp:399] data -> data
I0822 19:51:51.604895 14094 net.cpp:399] data -> label
I0822 19:51:51.605460 14132 db_lmdb.cpp:35] Opened lmdb examples/jr-station/img_part_test_lmdb
I0822 19:51:51.605583 14094 data_layer.cpp:41] output data size: 200,1,32,100
I0822 19:51:51.608737 14094 net.cpp:141] Setting up data
I0822 19:51:51.608757 14094 net.cpp:148] Top shape: 200 1 32 100 (640000)
I0822 19:51:51.608762 14094 net.cpp:148] Top shape: 200 (200)
I0822 19:51:51.608763 14094 net.cpp:156] Memory required for data: 2560800
I0822 19:51:51.608767 14094 layer_factory.hpp:77] Creating layer conv1
I0822 19:51:51.608779 14094 net.cpp:91] Creating Layer conv1
I0822 19:51:51.608783 14094 net.cpp:425] conv1 <- data
I0822 19:51:51.608789 14094 net.cpp:399] conv1 -> conv1
I0822 19:51:51.610008 14094 net.cpp:141] Setting up conv1
I0822 19:51:51.610019 14094 net.cpp:148] Top shape: 200 64 32 100 (40960000)
I0822 19:51:51.610023 14094 net.cpp:156] Memory required for data: 166400800
I0822 19:51:51.610029 14094 layer_factory.hpp:77] Creating layer relu1
I0822 19:51:51.610034 14094 net.cpp:91] Creating Layer relu1
I0822 19:51:51.610039 14094 net.cpp:425] relu1 <- conv1
I0822 19:51:51.610045 14094 net.cpp:386] relu1 -> conv1 (in-place)
I0822 19:51:51.610249 14094 net.cpp:141] Setting up relu1
I0822 19:51:51.610257 14094 net.cpp:148] Top shape: 200 64 32 100 (40960000)
I0822 19:51:51.610260 14094 net.cpp:156] Memory required for data: 330240800
I0822 19:51:51.610262 14094 layer_factory.hpp:77] Creating layer pool1
I0822 19:51:51.610267 14094 net.cpp:91] Creating Layer pool1
I0822 19:51:51.610270 14094 net.cpp:425] pool1 <- conv1
I0822 19:51:51.610275 14094 net.cpp:399] pool1 -> pool1
I0822 19:51:51.610304 14094 net.cpp:141] Setting up pool1
I0822 19:51:51.610308 14094 net.cpp:148] Top shape: 200 64 16 50 (10240000)
I0822 19:51:51.610311 14094 net.cpp:156] Memory required for data: 371200800
I0822 19:51:51.610319 14094 layer_factory.hpp:77] Creating layer conv2
I0822 19:51:51.610327 14094 net.cpp:91] Creating Layer conv2
I0822 19:51:51.610329 14094 net.cpp:425] conv2 <- pool1
I0822 19:51:51.610334 14094 net.cpp:399] conv2 -> conv2
I0822 19:51:51.616597 14094 net.cpp:141] Setting up conv2
I0822 19:51:51.616612 14094 net.cpp:148] Top shape: 200 128 16 50 (20480000)
I0822 19:51:51.616617 14094 net.cpp:156] Memory required for data: 453120800
I0822 19:51:51.616626 14094 layer_factory.hpp:77] Creating layer relu2
I0822 19:51:51.616636 14094 net.cpp:91] Creating Layer relu2
I0822 19:51:51.616639 14094 net.cpp:425] relu2 <- conv2
I0822 19:51:51.616647 14094 net.cpp:386] relu2 -> conv2 (in-place)
I0822 19:51:51.616767 14094 net.cpp:141] Setting up relu2
I0822 19:51:51.616775 14094 net.cpp:148] Top shape: 200 128 16 50 (20480000)
I0822 19:51:51.616777 14094 net.cpp:156] Memory required for data: 535040800
I0822 19:51:51.616780 14094 layer_factory.hpp:77] Creating layer pool2
I0822 19:51:51.616786 14094 net.cpp:91] Creating Layer pool2
I0822 19:51:51.616788 14094 net.cpp:425] pool2 <- conv2
I0822 19:51:51.616791 14094 net.cpp:399] pool2 -> pool2
I0822 19:51:51.616822 14094 net.cpp:141] Setting up pool2
I0822 19:51:51.616827 14094 net.cpp:148] Top shape: 200 128 8 25 (5120000)
I0822 19:51:51.616828 14094 net.cpp:156] Memory required for data: 555520800
I0822 19:51:51.616830 14094 layer_factory.hpp:77] Creating layer conv3
I0822 19:51:51.616838 14094 net.cpp:91] Creating Layer conv3
I0822 19:51:51.616840 14094 net.cpp:425] conv3 <- pool2
I0822 19:51:51.616845 14094 net.cpp:399] conv3 -> conv3
I0822 19:51:51.623597 14094 net.cpp:141] Setting up conv3
I0822 19:51:51.623607 14094 net.cpp:148] Top shape: 200 256 8 25 (10240000)
I0822 19:51:51.623611 14094 net.cpp:156] Memory required for data: 596480800
I0822 19:51:51.623618 14094 layer_factory.hpp:77] Creating layer relu3
I0822 19:51:51.623623 14094 net.cpp:91] Creating Layer relu3
I0822 19:51:51.623627 14094 net.cpp:425] relu3 <- conv3
I0822 19:51:51.623631 14094 net.cpp:386] relu3 -> conv3 (in-place)
I0822 19:51:51.623823 14094 net.cpp:141] Setting up relu3
I0822 19:51:51.623831 14094 net.cpp:148] Top shape: 200 256 8 25 (10240000)
I0822 19:51:51.623833 14094 net.cpp:156] Memory required for data: 637440800
I0822 19:51:51.623836 14094 layer_factory.hpp:77] Creating layer conv3_5
I0822 19:51:51.623843 14094 net.cpp:91] Creating Layer conv3_5
I0822 19:51:51.623847 14094 net.cpp:425] conv3_5 <- conv3
I0822 19:51:51.623852 14094 net.cpp:399] conv3_5 -> conv3_5
I0822 19:51:51.648480 14094 net.cpp:141] Setting up conv3_5
I0822 19:51:51.648499 14094 net.cpp:148] Top shape: 200 512 8 25 (20480000)
I0822 19:51:51.648501 14094 net.cpp:156] Memory required for data: 719360800
I0822 19:51:51.648507 14094 layer_factory.hpp:77] Creating layer relu3_5
I0822 19:51:51.648514 14094 net.cpp:91] Creating Layer relu3_5
I0822 19:51:51.648517 14094 net.cpp:425] relu3_5 <- conv3_5
I0822 19:51:51.648521 14094 net.cpp:386] relu3_5 -> conv3_5 (in-place)
I0822 19:51:51.648710 14094 net.cpp:141] Setting up relu3_5
I0822 19:51:51.648718 14094 net.cpp:148] Top shape: 200 512 8 25 (20480000)
I0822 19:51:51.648721 14094 net.cpp:156] Memory required for data: 801280800
I0822 19:51:51.648723 14094 layer_factory.hpp:77] Creating layer pool3
I0822 19:51:51.648728 14094 net.cpp:91] Creating Layer pool3
I0822 19:51:51.648741 14094 net.cpp:425] pool3 <- conv3_5
I0822 19:51:51.648746 14094 net.cpp:399] pool3 -> pool3
I0822 19:51:51.648780 14094 net.cpp:141] Setting up pool3
I0822 19:51:51.648785 14094 net.cpp:148] Top shape: 200 512 4 13 (5324800)
I0822 19:51:51.648788 14094 net.cpp:156] Memory required for data: 822580000
I0822 19:51:51.648790 14094 layer_factory.hpp:77] Creating layer conv4
I0822 19:51:51.648797 14094 net.cpp:91] Creating Layer conv4
I0822 19:51:51.648800 14094 net.cpp:425] conv4 <- pool3
I0822 19:51:51.648805 14094 net.cpp:399] conv4 -> conv4
I0822 19:51:51.697389 14094 net.cpp:141] Setting up conv4
I0822 19:51:51.697408 14094 net.cpp:148] Top shape: 200 512 4 13 (5324800)
I0822 19:51:51.697412 14094 net.cpp:156] Memory required for data: 843879200
I0822 19:51:51.697419 14094 layer_factory.hpp:77] Creating layer relu4
I0822 19:51:51.697427 14094 net.cpp:91] Creating Layer relu4
I0822 19:51:51.697429 14094 net.cpp:425] relu4 <- conv4
I0822 19:51:51.697433 14094 net.cpp:386] relu4 -> conv4 (in-place)
I0822 19:51:51.697552 14094 net.cpp:141] Setting up relu4
I0822 19:51:51.697561 14094 net.cpp:148] Top shape: 200 512 4 13 (5324800)
I0822 19:51:51.697562 14094 net.cpp:156] Memory required for data: 865178400
I0822 19:51:51.697564 14094 layer_factory.hpp:77] Creating layer fc1
I0822 19:51:51.697573 14094 net.cpp:91] Creating Layer fc1
I0822 19:51:51.697576 14094 net.cpp:425] fc1 <- conv4
I0822 19:51:51.697580 14094 net.cpp:399] fc1 -> fc1
I0822 19:51:53.901566 14094 net.cpp:141] Setting up fc1
I0822 19:51:53.901585 14094 net.cpp:148] Top shape: 200 4096 1 1 (819200)
I0822 19:51:53.901588 14094 net.cpp:156] Memory required for data: 868455200
I0822 19:51:53.901594 14094 layer_factory.hpp:77] Creating layer relu5
I0822 19:51:53.901600 14094 net.cpp:91] Creating Layer relu5
I0822 19:51:53.901603 14094 net.cpp:425] relu5 <- fc1
I0822 19:51:53.901607 14094 net.cpp:386] relu5 -> fc1 (in-place)
I0822 19:51:53.901806 14094 net.cpp:141] Setting up relu5
I0822 19:51:53.901815 14094 net.cpp:148] Top shape: 200 4096 1 1 (819200)
I0822 19:51:53.901818 14094 net.cpp:156] Memory required for data: 871732000
I0822 19:51:53.901820 14094 layer_factory.hpp:77] Creating layer fc2
I0822 19:51:53.901830 14094 net.cpp:91] Creating Layer fc2
I0822 19:51:53.901834 14094 net.cpp:425] fc2 <- fc1
I0822 19:51:53.901837 14094 net.cpp:399] fc2 -> fc2
I0822 19:51:54.242168 14094 net.cpp:141] Setting up fc2
I0822 19:51:54.242185 14094 net.cpp:148] Top shape: 200 4096 1 1 (819200)
I0822 19:51:54.242188 14094 net.cpp:156] Memory required for data: 875008800
I0822 19:51:54.242195 14094 layer_factory.hpp:77] Creating layer relu6
I0822 19:51:54.242202 14094 net.cpp:91] Creating Layer relu6
I0822 19:51:54.242204 14094 net.cpp:425] relu6 <- fc2
I0822 19:51:54.242208 14094 net.cpp:386] relu6 -> fc2 (in-place)
I0822 19:51:54.242399 14094 net.cpp:141] Setting up relu6
I0822 19:51:54.242408 14094 net.cpp:148] Top shape: 200 4096 1 1 (819200)
I0822 19:51:54.242410 14094 net.cpp:156] Memory required for data: 878285600
I0822 19:51:54.242413 14094 layer_factory.hpp:77] Creating layer fc_class
I0822 19:51:54.242421 14094 net.cpp:91] Creating Layer fc_class
I0822 19:51:54.242424 14094 net.cpp:425] fc_class <- fc2
I0822 19:51:54.242429 14094 net.cpp:399] fc_class -> fc_class
I0822 19:52:01.541563 14094 net.cpp:141] Setting up fc_class
I0822 19:52:01.541579 14094 net.cpp:148] Top shape: 200 88172 1 1 (17634400)
I0822 19:52:01.541582 14094 net.cpp:156] Memory required for data: 948823200
I0822 19:52:01.541589 14094 layer_factory.hpp:77] Creating layer fc_class_fc_class_0_split
I0822 19:52:01.541596 14094 net.cpp:91] Creating Layer fc_class_fc_class_0_split
I0822 19:52:01.541599 14094 net.cpp:425] fc_class_fc_class_0_split <- fc_class
I0822 19:52:01.541604 14094 net.cpp:399] fc_class_fc_class_0_split -> fc_class_fc_class_0_split_0
I0822 19:52:01.541610 14094 net.cpp:399] fc_class_fc_class_0_split -> fc_class_fc_class_0_split_1
I0822 19:52:01.541646 14094 net.cpp:141] Setting up fc_class_fc_class_0_split
I0822 19:52:01.541651 14094 net.cpp:148] Top shape: 200 88172 1 1 (17634400)
I0822 19:52:01.541666 14094 net.cpp:148] Top shape: 200 88172 1 1 (17634400)
I0822 19:52:01.541667 14094 net.cpp:156] Memory required for data: 1089898400
I0822 19:52:01.541671 14094 layer_factory.hpp:77] Creating layer prob
I0822 19:52:01.541674 14094 net.cpp:91] Creating Layer prob
I0822 19:52:01.541677 14094 net.cpp:425] prob <- fc_class_fc_class_0_split_0
I0822 19:52:01.541682 14094 net.cpp:399] prob -> prob
I0822 19:52:01.542106 14094 net.cpp:141] Setting up prob
I0822 19:52:01.542115 14094 net.cpp:148] Top shape: 200 88172 1 1 (17634400)
I0822 19:52:01.542117 14094 net.cpp:156] Memory required for data: 1160436000
I0822 19:52:01.542120 14094 layer_factory.hpp:77] Creating layer loss
I0822 19:52:01.542124 14094 net.cpp:91] Creating Layer loss
I0822 19:52:01.542126 14094 net.cpp:425] loss <- fc_class_fc_class_0_split_1
I0822 19:52:01.542129 14094 net.cpp:425] loss <- label
I0822 19:52:01.542135 14094 net.cpp:399] loss -> loss
I0822 19:52:01.542141 14094 layer_factory.hpp:77] Creating layer loss
I0822 19:52:01.562012 14094 net.cpp:141] Setting up loss
I0822 19:52:01.562032 14094 net.cpp:148] Top shape: (1)
I0822 19:52:01.562036 14094 net.cpp:151]     with loss weight 1
I0822 19:52:01.562042 14094 net.cpp:156] Memory required for data: 1160436004
I0822 19:52:01.562047 14094 net.cpp:217] loss needs backward computation.
I0822 19:52:01.562049 14094 net.cpp:219] prob does not need backward computation.
I0822 19:52:01.562052 14094 net.cpp:217] fc_class_fc_class_0_split needs backward computation.
I0822 19:52:01.562055 14094 net.cpp:217] fc_class needs backward computation.
I0822 19:52:01.562058 14094 net.cpp:217] relu6 needs backward computation.
I0822 19:52:01.562060 14094 net.cpp:217] fc2 needs backward computation.
I0822 19:52:01.562062 14094 net.cpp:217] relu5 needs backward computation.
I0822 19:52:01.562065 14094 net.cpp:217] fc1 needs backward computation.
I0822 19:52:01.562067 14094 net.cpp:217] relu4 needs backward computation.
I0822 19:52:01.562070 14094 net.cpp:217] conv4 needs backward computation.
I0822 19:52:01.562072 14094 net.cpp:217] pool3 needs backward computation.
I0822 19:52:01.562074 14094 net.cpp:217] relu3_5 needs backward computation.
I0822 19:52:01.562078 14094 net.cpp:217] conv3_5 needs backward computation.
I0822 19:52:01.562083 14094 net.cpp:217] relu3 needs backward computation.
I0822 19:52:01.562088 14094 net.cpp:217] conv3 needs backward computation.
I0822 19:52:01.562093 14094 net.cpp:217] pool2 needs backward computation.
I0822 19:52:01.562095 14094 net.cpp:217] relu2 needs backward computation.
I0822 19:52:01.562098 14094 net.cpp:217] conv2 needs backward computation.
I0822 19:52:01.562100 14094 net.cpp:217] pool1 needs backward computation.
I0822 19:52:01.562103 14094 net.cpp:217] relu1 needs backward computation.
I0822 19:52:01.562105 14094 net.cpp:217] conv1 needs backward computation.
I0822 19:52:01.562108 14094 net.cpp:219] data does not need backward computation.
I0822 19:52:01.562109 14094 net.cpp:261] This network produces output loss
I0822 19:52:01.562114 14094 net.cpp:261] This network produces output prob
I0822 19:52:01.562124 14094 net.cpp:274] Network initialization done.
I0822 19:52:01.562186 14094 solver.cpp:60] Solver scaffolding done.
I0822 19:52:01.562613 14094 caffe.cpp:129] Finetuning from examples/jr-station/pre.caffemodel
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:604] Reading dangerously large protocol message.  If the message turns out to be larger than 2147483647 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:81] The total number of bytes read was 1964480478
I0822 19:52:42.220100 14094 upgrade_proto.cpp:66] Attempting to upgrade input file specified using deprecated input fields: examples/jr-station/pre.caffemodel
I0822 19:52:42.220134 14094 upgrade_proto.cpp:69] Successfully upgraded file specified using deprecated input fields.
W0822 19:52:42.220139 14094 upgrade_proto.cpp:71] Note that future Caffe releases will only support input layers and not input fields.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:604] Reading dangerously large protocol message.  If the message turns out to be larger than 2147483647 bytes, parsing will be halted for security reasons.  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.
[libprotobuf WARNING google/protobuf/io/coded_stream.cc:81] The total number of bytes read was 1964480478
I0822 19:52:44.384523 14094 upgrade_proto.cpp:66] Attempting to upgrade input file specified using deprecated input fields: examples/jr-station/pre.caffemodel
I0822 19:52:44.384536 14094 upgrade_proto.cpp:69] Successfully upgraded file specified using deprecated input fields.
W0822 19:52:44.384538 14094 upgrade_proto.cpp:71] Note that future Caffe releases will only support input layers and not input fields.
I0822 19:52:44.689363 14094 caffe.cpp:219] Starting Optimization
I0822 19:52:44.689383 14094 solver.cpp:280] Solving Bigram_Net_VGG
I0822 19:52:44.689386 14094 solver.cpp:281] Learning Rate Policy: step
I0822 19:52:44.695443 14094 solver.cpp:338] Iteration 0, Testing net (#0)
I0822 19:54:55.260694 14094 solver.cpp:406]     Test net output #0: loss = 1.5026 (* 1 = 1.5026 loss)
I0822 19:54:55.462998 14094 solver.cpp:406]     Test net output #1000000: prob = 2.23207e-06
I0822 19:54:55.664819 14094 solver.cpp:406]     Test net output #2000000: prob = 4.30451e-06
I0822 19:54:55.866612 14094 solver.cpp:406]     Test net output #3000000: prob = 1.1597e-06
I0822 19:54:56.068361 14094 solver.cpp:406]     Test net output #4000000: prob = 1.87618e-06
I0822 19:54:56.270162 14094 solver.cpp:406]     Test net output #5000000: prob = 0.000128249
I0822 19:54:56.472646 14094 solver.cpp:406]     Test net output #6000000: prob = 1.46278e-06
I0822 19:54:56.675035 14094 solver.cpp:406]     Test net output #7000000: prob = 2.10637e-06
I0822 19:54:56.877563 14094 solver.cpp:406]     Test net output #8000000: prob = 3.28532e-06
I0822 19:54:57.079509 14094 solver.cpp:406]     Test net output #9000000: prob = 1.27351e-06
I0822 19:54:57.281347 14094 solver.cpp:406]     Test net output #10000000: prob = 1.46961e-06
I0822 19:54:57.483889 14094 solver.cpp:406]     Test net output #11000000: prob = 2.18098e-06
I0822 19:54:57.685837 14094 solver.cpp:406]     Test net output #12000000: prob = 2.22373e-06
I0822 19:54:57.888320 14094 solver.cpp:406]     Test net output #13000000: prob = 1.78956e-06
I0822 19:54:58.090651 14094 solver.cpp:406]     Test net output #14000000: prob = 3.56244e-06
I0822 19:54:58.293301 14094 solver.cpp:406]     Test net output #15000000: prob = 6.16797e-06
I0822 19:54:58.495177 14094 solver.cpp:406]     Test net output #16000000: prob = 2.29058e-06
I0822 19:54:58.696933 14094 solver.cpp:406]     Test net output #17000000: prob = 3.0314e-06
I0822 19:54:59.207046 14094 solver.cpp:228] Iteration 0, loss = 1.60121
I0822 19:54:59.207070 14094 solver.cpp:245]     Train net output #0: loss = 1.60121 (* 1 = 1.60121 loss)
I0822 19:55:19.103260 14094 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0822 20:04:53.617866 14094 solver.cpp:228] Iteration 50, loss = 1.0532
I0822 20:04:53.617971 14094 solver.cpp:245]     Train net output #0: loss = 1.0532 (* 1 = 1.0532 loss)
I0822 20:05:13.797662 14094 sgd_solver.cpp:106] Iteration 50, lr = 0.001
I0822 20:14:50.614799 14094 solver.cpp:228] Iteration 100, loss = 0.684268
I0822 20:14:50.614904 14094 solver.cpp:245]     Train net output #0: loss = 0.684268 (* 1 = 0.684268 loss)
I0822 20:15:11.303550 14094 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I0822 20:24:50.563951 14094 solver.cpp:228] Iteration 150, loss = 0.657899
I0822 20:24:50.564029 14094 solver.cpp:245]     Train net output #0: loss = 0.657899 (* 1 = 0.657899 loss)
I0822 20:25:10.756666 14094 sgd_solver.cpp:106] Iteration 150, lr = 0.001
I0822 20:34:51.772529 14094 solver.cpp:228] Iteration 200, loss = 0.592777
I0822 20:34:51.772580 14094 solver.cpp:245]     Train net output #0: loss = 0.592777 (* 1 = 0.592777 loss)
I0822 20:35:12.506386 14094 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I0822 20:44:54.552191 14094 solver.cpp:228] Iteration 250, loss = 0.455176
I0822 20:44:54.552299 14094 solver.cpp:245]     Train net output #0: loss = 0.455176 (* 1 = 0.455176 loss)
I0822 20:45:14.888509 14094 sgd_solver.cpp:106] Iteration 250, lr = 0.001
I0822 20:54:58.362620 14094 solver.cpp:228] Iteration 300, loss = 0.512654
I0822 20:54:58.362728 14094 solver.cpp:245]     Train net output #0: loss = 0.512654 (* 1 = 0.512654 loss)
I0822 20:55:19.233113 14094 sgd_solver.cpp:106] Iteration 300, lr = 0.001
I0822 21:05:02.373154 14094 solver.cpp:228] Iteration 350, loss = 0.780876
I0822 21:05:02.373201 14094 solver.cpp:245]     Train net output #0: loss = 0.780876 (* 1 = 0.780876 loss)
I0822 21:05:22.601627 14094 sgd_solver.cpp:106] Iteration 350, lr = 0.001
I0822 21:15:04.198357 14094 solver.cpp:228] Iteration 400, loss = 0.626274
I0822 21:15:04.198439 14094 solver.cpp:245]     Train net output #0: loss = 0.626274 (* 1 = 0.626274 loss)
I0822 21:15:24.702720 14094 sgd_solver.cpp:106] Iteration 400, lr = 0.001
I0822 21:25:07.298157 14094 solver.cpp:228] Iteration 450, loss = 0.701079
I0822 21:25:07.298231 14094 solver.cpp:245]     Train net output #0: loss = 0.701079 (* 1 = 0.701079 loss)
I0822 21:25:27.562852 14094 sgd_solver.cpp:106] Iteration 450, lr = 0.001
I0822 21:35:11.750247 14094 solver.cpp:228] Iteration 500, loss = 0.503625
I0822 21:35:11.750362 14094 solver.cpp:245]     Train net output #0: loss = 0.503625 (* 1 = 0.503625 loss)
I0822 21:35:32.669344 14094 sgd_solver.cpp:106] Iteration 500, lr = 0.001
I0822 21:45:17.589399 14094 solver.cpp:228] Iteration 550, loss = 0.459808
I0822 21:45:17.590206 14094 solver.cpp:245]     Train net output #0: loss = 0.459808 (* 1 = 0.459808 loss)
I0822 21:45:38.359519 14094 sgd_solver.cpp:106] Iteration 550, lr = 0.001
I0822 21:55:22.189959 14094 solver.cpp:228] Iteration 600, loss = 0.572105
I0822 21:55:22.190731 14094 solver.cpp:245]     Train net output #0: loss = 0.572105 (* 1 = 0.572105 loss)
I0822 21:55:42.515043 14094 sgd_solver.cpp:106] Iteration 600, lr = 0.001
I0822 22:05:27.417011 14094 solver.cpp:228] Iteration 650, loss = 0.480449
I0822 22:05:27.417126 14094 solver.cpp:245]     Train net output #0: loss = 0.480449 (* 1 = 0.480449 loss)
I0822 22:05:47.733355 14094 sgd_solver.cpp:106] Iteration 650, lr = 0.001
I0822 22:15:31.661077 14094 solver.cpp:228] Iteration 700, loss = 0.541653
I0822 22:15:31.661183 14094 solver.cpp:245]     Train net output #0: loss = 0.541653 (* 1 = 0.541653 loss)
I0822 22:15:51.988765 14094 sgd_solver.cpp:106] Iteration 700, lr = 0.001
I0822 22:25:35.256244 14094 solver.cpp:228] Iteration 750, loss = 0.434773
I0822 22:25:35.256366 14094 solver.cpp:245]     Train net output #0: loss = 0.434773 (* 1 = 0.434773 loss)
I0822 22:25:56.012854 14094 sgd_solver.cpp:106] Iteration 750, lr = 0.001
I0822 22:35:39.522204 14094 solver.cpp:228] Iteration 800, loss = 0.485991
I0822 22:35:39.522313 14094 solver.cpp:245]     Train net output #0: loss = 0.485991 (* 1 = 0.485991 loss)
I0822 22:36:00.136304 14094 sgd_solver.cpp:106] Iteration 800, lr = 0.001
I0822 22:45:43.614312 14094 solver.cpp:228] Iteration 850, loss = 0.495409
I0822 22:45:43.614385 14094 solver.cpp:245]     Train net output #0: loss = 0.495409 (* 1 = 0.495409 loss)
I0822 22:46:03.821769 14094 sgd_solver.cpp:106] Iteration 850, lr = 0.001
I0822 22:55:48.391166 14094 solver.cpp:228] Iteration 900, loss = 0.692684
I0822 22:55:48.391208 14094 solver.cpp:245]     Train net output #0: loss = 0.692684 (* 1 = 0.692684 loss)
I0822 22:56:08.973170 14094 sgd_solver.cpp:106] Iteration 900, lr = 0.001
I0822 23:05:54.631175 14094 solver.cpp:228] Iteration 950, loss = 0.515724
I0822 23:05:54.631216 14094 solver.cpp:245]     Train net output #0: loss = 0.515724 (* 1 = 0.515724 loss)
I0822 23:06:15.134544 14094 sgd_solver.cpp:106] Iteration 950, lr = 0.001
I0822 23:15:47.621214 14094 solver.cpp:338] Iteration 1000, Testing net (#0)
I0822 23:18:17.656404 14094 solver.cpp:406]     Test net output #0: loss = 0.452167 (* 1 = 0.452167 loss)
I0822 23:18:17.859163 14094 solver.cpp:406]     Test net output #1000000: prob = 3.18121e-07
I0822 23:18:18.061640 14094 solver.cpp:406]     Test net output #2000000: prob = 3.78302e-06
I0822 23:18:18.263662 14094 solver.cpp:406]     Test net output #3000000: prob = 4.51902e-08
I0822 23:18:18.466121 14094 solver.cpp:406]     Test net output #4000000: prob = 3.3605e-07
I0822 23:18:18.668632 14094 solver.cpp:406]     Test net output #5000000: prob = 1.87059e-07
I0822 23:18:18.870774 14094 solver.cpp:406]     Test net output #6000000: prob = 3.74184e-07
I0822 23:18:19.073493 14094 solver.cpp:406]     Test net output #7000000: prob = 2.77604e-06
I0822 23:18:19.275342 14094 solver.cpp:406]     Test net output #8000000: prob = 3.10584e-06
I0822 23:18:19.477766 14094 solver.cpp:406]     Test net output #9000000: prob = 8.73949e-08
I0822 23:18:19.680217 14094 solver.cpp:406]     Test net output #10000000: prob = 3.16752e-07
I0822 23:18:19.882151 14094 solver.cpp:406]     Test net output #11000000: prob = 2.75695e-07
I0822 23:18:20.084084 14094 solver.cpp:406]     Test net output #12000000: prob = 1.40763e-06
I0822 23:18:20.285961 14094 solver.cpp:406]     Test net output #13000000: prob = 1.26545e-06
I0822 23:18:20.487879 14094 solver.cpp:406]     Test net output #14000000: prob = 2.14919e-06
I0822 23:18:20.689838 14094 solver.cpp:406]     Test net output #15000000: prob = 1.18367e-07
I0822 23:18:20.891758 14094 solver.cpp:406]     Test net output #16000000: prob = 3.4758e-07
I0822 23:18:21.094342 14094 solver.cpp:406]     Test net output #17000000: prob = 3.56457e-07
I0822 23:18:21.556746 14094 solver.cpp:228] Iteration 1000, loss = 0.523951
I0822 23:18:21.556771 14094 solver.cpp:245]     Train net output #0: loss = 0.523951 (* 1 = 0.523951 loss)
I0822 23:18:41.480710 14094 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I0822 23:28:22.425266 14094 solver.cpp:228] Iteration 1050, loss = 0.533886
I0822 23:28:22.425391 14094 solver.cpp:245]     Train net output #0: loss = 0.533886 (* 1 = 0.533886 loss)
I0822 23:28:43.220499 14094 sgd_solver.cpp:106] Iteration 1050, lr = 0.001
I0822 23:38:27.510695 14094 solver.cpp:228] Iteration 1100, loss = 0.626009
I0822 23:38:27.510749 14094 solver.cpp:245]     Train net output #0: loss = 0.626009 (* 1 = 0.626009 loss)
I0822 23:38:47.949856 14094 sgd_solver.cpp:106] Iteration 1100, lr = 0.001
I0822 23:48:31.956568 14094 solver.cpp:228] Iteration 1150, loss = 0.809958
I0822 23:48:31.956671 14094 solver.cpp:245]     Train net output #0: loss = 0.809958 (* 1 = 0.809958 loss)
I0822 23:48:52.724346 14094 sgd_solver.cpp:106] Iteration 1150, lr = 0.001
I0822 23:58:37.514274 14094 solver.cpp:228] Iteration 1200, loss = 0.475759
I0822 23:58:37.514348 14094 solver.cpp:245]     Train net output #0: loss = 0.475759 (* 1 = 0.475759 loss)
I0822 23:58:58.294281 14094 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I0823 00:08:43.291293 14094 solver.cpp:228] Iteration 1250, loss = 0.571759
I0823 00:08:43.291404 14094 solver.cpp:245]     Train net output #0: loss = 0.571759 (* 1 = 0.571759 loss)
I0823 00:09:03.877182 14094 sgd_solver.cpp:106] Iteration 1250, lr = 0.001
I0823 00:18:49.532562 14094 solver.cpp:228] Iteration 1300, loss = 0.534031
I0823 00:18:49.532610 14094 solver.cpp:245]     Train net output #0: loss = 0.534031 (* 1 = 0.534031 loss)
I0823 00:19:10.391820 14094 sgd_solver.cpp:106] Iteration 1300, lr = 0.001
I0823 00:28:55.344887 14094 solver.cpp:228] Iteration 1350, loss = 0.585833
I0823 00:28:55.344960 14094 solver.cpp:245]     Train net output #0: loss = 0.585833 (* 1 = 0.585833 loss)
I0823 00:29:15.651006 14094 sgd_solver.cpp:106] Iteration 1350, lr = 0.001
I0823 00:39:00.244451 14094 solver.cpp:228] Iteration 1400, loss = 0.544153
I0823 00:39:00.244530 14094 solver.cpp:245]     Train net output #0: loss = 0.544153 (* 1 = 0.544153 loss)
I0823 00:39:21.038370 14094 sgd_solver.cpp:106] Iteration 1400, lr = 0.001
I0823 00:49:06.340560 14094 solver.cpp:228] Iteration 1450, loss = 0.419198
I0823 00:49:06.340608 14094 solver.cpp:245]     Train net output #0: loss = 0.419198 (* 1 = 0.419198 loss)
I0823 00:49:27.252472 14094 sgd_solver.cpp:106] Iteration 1450, lr = 0.001
I0823 00:59:12.754516 14094 solver.cpp:228] Iteration 1500, loss = 0.553411
I0823 00:59:12.754626 14094 solver.cpp:245]     Train net output #0: loss = 0.553411 (* 1 = 0.553411 loss)
I0823 00:59:33.604564 14094 sgd_solver.cpp:106] Iteration 1500, lr = 0.001
I0823 01:09:18.837455 14094 solver.cpp:228] Iteration 1550, loss = 0.344868
I0823 01:09:18.837524 14094 solver.cpp:245]     Train net output #0: loss = 0.344868 (* 1 = 0.344868 loss)
I0823 01:09:39.131472 14094 sgd_solver.cpp:106] Iteration 1550, lr = 0.001
I0823 01:19:23.574472 14094 solver.cpp:228] Iteration 1600, loss = 0.449367
I0823 01:19:23.574592 14094 solver.cpp:245]     Train net output #0: loss = 0.449367 (* 1 = 0.449367 loss)
I0823 01:19:43.929775 14094 sgd_solver.cpp:106] Iteration 1600, lr = 0.001
I0823 01:29:28.990262 14094 solver.cpp:228] Iteration 1650, loss = 0.470354
I0823 01:29:28.991153 14094 solver.cpp:245]     Train net output #0: loss = 0.470354 (* 1 = 0.470354 loss)
I0823 01:29:49.875056 14094 sgd_solver.cpp:106] Iteration 1650, lr = 0.001
I0823 01:39:36.417498 14094 solver.cpp:228] Iteration 1700, loss = 0.612753
I0823 01:39:36.417613 14094 solver.cpp:245]     Train net output #0: loss = 0.612753 (* 1 = 0.612753 loss)
I0823 01:39:57.364917 14094 sgd_solver.cpp:106] Iteration 1700, lr = 0.001
I0823 01:49:43.998461 14094 solver.cpp:228] Iteration 1750, loss = 0.52576
I0823 01:49:43.998575 14094 solver.cpp:245]     Train net output #0: loss = 0.52576 (* 1 = 0.52576 loss)
I0823 01:50:04.380121 14094 sgd_solver.cpp:106] Iteration 1750, lr = 0.001
I0823 01:59:50.495143 14094 solver.cpp:228] Iteration 1800, loss = 0.440899
I0823 01:59:50.495255 14094 solver.cpp:245]     Train net output #0: loss = 0.440899 (* 1 = 0.440899 loss)
I0823 02:00:11.342072 14094 sgd_solver.cpp:106] Iteration 1800, lr = 0.001
I0823 02:09:57.615080 14094 solver.cpp:228] Iteration 1850, loss = 0.382559
I0823 02:09:57.615967 14094 solver.cpp:245]     Train net output #0: loss = 0.382559 (* 1 = 0.382559 loss)
I0823 02:10:17.926494 14094 sgd_solver.cpp:106] Iteration 1850, lr = 0.001
I0823 02:20:04.641084 14094 solver.cpp:228] Iteration 1900, loss = 0.398715
I0823 02:20:04.641191 14094 solver.cpp:245]     Train net output #0: loss = 0.398715 (* 1 = 0.398715 loss)
I0823 02:20:25.555408 14094 sgd_solver.cpp:106] Iteration 1900, lr = 0.001
I0823 02:30:12.295966 14094 solver.cpp:228] Iteration 1950, loss = 0.298917
I0823 02:30:12.296067 14094 solver.cpp:245]     Train net output #0: loss = 0.298917 (* 1 = 0.298917 loss)
I0823 02:30:32.651296 14094 sgd_solver.cpp:106] Iteration 1950, lr = 0.001
I0823 02:40:06.922953 14094 solver.cpp:338] Iteration 2000, Testing net (#0)
I0823 02:42:39.948308 14094 solver.cpp:406]     Test net output #0: loss = 0.412408 (* 1 = 0.412408 loss)
I0823 02:42:40.151000 14094 solver.cpp:406]     Test net output #1000000: prob = 4.18071e-07
I0823 02:42:40.353111 14094 solver.cpp:406]     Test net output #2000000: prob = 2.43899e-07
I0823 02:42:40.555279 14094 solver.cpp:406]     Test net output #3000000: prob = 2.60268e-08
I0823 02:42:40.757179 14094 solver.cpp:406]     Test net output #4000000: prob = 1.93497e-07
I0823 02:42:40.959345 14094 solver.cpp:406]     Test net output #5000000: prob = 1.72497e-07
I0823 02:42:41.161188 14094 solver.cpp:406]     Test net output #6000000: prob = 2.18967e-07
I0823 02:42:41.363095 14094 solver.cpp:406]     Test net output #7000000: prob = 3.9656e-07
I0823 02:42:41.564920 14094 solver.cpp:406]     Test net output #8000000: prob = 1.97602e-06
I0823 02:42:41.766948 14094 solver.cpp:406]     Test net output #9000000: prob = 4.15012e-08
I0823 02:42:41.968935 14094 solver.cpp:406]     Test net output #10000000: prob = 2.99012e-07
I0823 02:42:42.170691 14094 solver.cpp:406]     Test net output #11000000: prob = 3.59083e-07
I0823 02:42:42.372468 14094 solver.cpp:406]     Test net output #12000000: prob = 5.71568e-07
I0823 02:42:42.574887 14094 solver.cpp:406]     Test net output #13000000: prob = 9.11717e-07
I0823 02:42:42.777315 14094 solver.cpp:406]     Test net output #14000000: prob = 2.12736e-07
I0823 02:42:42.979334 14094 solver.cpp:406]     Test net output #15000000: prob = 9.35867e-08
I0823 02:42:43.181680 14094 solver.cpp:406]     Test net output #16000000: prob = 5.17265e-07
I0823 02:42:43.383574 14094 solver.cpp:406]     Test net output #17000000: prob = 4.62713e-07
I0823 02:42:43.850860 14094 solver.cpp:228] Iteration 2000, loss = 0.342737
I0823 02:42:43.850888 14094 solver.cpp:245]     Train net output #0: loss = 0.342737 (* 1 = 0.342737 loss)
I0823 02:43:04.245968 14094 sgd_solver.cpp:106] Iteration 2000, lr = 0.0001
I0823 02:52:47.166388 14094 solver.cpp:228] Iteration 2050, loss = 0.356111
I0823 02:52:47.166497 14094 solver.cpp:245]     Train net output #0: loss = 0.356111 (* 1 = 0.356111 loss)
I0823 02:53:07.565066 14094 sgd_solver.cpp:106] Iteration 2050, lr = 0.0001
I0823 03:02:54.280762 14094 solver.cpp:228] Iteration 2100, loss = 0.328978
I0823 03:02:54.280850 14094 solver.cpp:245]     Train net output #0: loss = 0.328978 (* 1 = 0.328978 loss)
I0823 03:03:14.606714 14094 sgd_solver.cpp:106] Iteration 2100, lr = 0.0001
I0823 03:13:00.642711 14094 solver.cpp:228] Iteration 2150, loss = 0.44767
I0823 03:13:00.642792 14094 solver.cpp:245]     Train net output #0: loss = 0.44767 (* 1 = 0.44767 loss)
I0823 03:13:21.486320 14094 sgd_solver.cpp:106] Iteration 2150, lr = 0.0001
I0823 03:23:07.640895 14094 solver.cpp:228] Iteration 2200, loss = 0.35516
I0823 03:23:07.640998 14094 solver.cpp:245]     Train net output #0: loss = 0.35516 (* 1 = 0.35516 loss)
I0823 03:23:28.115373 14094 sgd_solver.cpp:106] Iteration 2200, lr = 0.0001
I0823 03:33:15.423058 14094 solver.cpp:228] Iteration 2250, loss = 0.315952
I0823 03:33:15.423166 14094 solver.cpp:245]     Train net output #0: loss = 0.315952 (* 1 = 0.315952 loss)
I0823 03:33:36.346756 14094 sgd_solver.cpp:106] Iteration 2250, lr = 0.0001
I0823 03:43:23.588810 14094 solver.cpp:228] Iteration 2300, loss = 0.312157
I0823 03:43:23.588919 14094 solver.cpp:245]     Train net output #0: loss = 0.312157 (* 1 = 0.312157 loss)
I0823 03:43:43.930102 14094 sgd_solver.cpp:106] Iteration 2300, lr = 0.0001
I0823 03:53:30.119369 14094 solver.cpp:228] Iteration 2350, loss = 0.336385
I0823 03:53:30.119454 14094 solver.cpp:245]     Train net output #0: loss = 0.336385 (* 1 = 0.336385 loss)
I0823 03:53:50.458114 14094 sgd_solver.cpp:106] Iteration 2350, lr = 0.0001
I0823 04:03:36.591962 14094 solver.cpp:228] Iteration 2400, loss = 0.422894
I0823 04:03:36.592042 14094 solver.cpp:245]     Train net output #0: loss = 0.422894 (* 1 = 0.422894 loss)
I0823 04:03:56.927547 14094 sgd_solver.cpp:106] Iteration 2400, lr = 0.0001
I0823 04:13:43.696035 14094 solver.cpp:228] Iteration 2450, loss = 0.402079
I0823 04:13:43.696138 14094 solver.cpp:245]     Train net output #0: loss = 0.402079 (* 1 = 0.402079 loss)
I0823 04:14:04.160231 14094 sgd_solver.cpp:106] Iteration 2450, lr = 0.0001
I0823 04:23:51.423614 14094 solver.cpp:228] Iteration 2500, loss = 0.421305
I0823 04:23:51.423704 14094 solver.cpp:245]     Train net output #0: loss = 0.421305 (* 1 = 0.421305 loss)
I0823 04:24:12.096745 14094 sgd_solver.cpp:106] Iteration 2500, lr = 0.0001
I0823 04:33:58.248049 14094 solver.cpp:228] Iteration 2550, loss = 0.356254
I0823 04:33:58.248141 14094 solver.cpp:245]     Train net output #0: loss = 0.356254 (* 1 = 0.356254 loss)
I0823 04:34:18.582758 14094 sgd_solver.cpp:106] Iteration 2550, lr = 0.0001
I0823 04:44:05.348520 14094 solver.cpp:228] Iteration 2600, loss = 0.304613
I0823 04:44:05.349290 14094 solver.cpp:245]     Train net output #0: loss = 0.304613 (* 1 = 0.304613 loss)
I0823 04:44:25.655539 14094 sgd_solver.cpp:106] Iteration 2600, lr = 0.0001
I0823 04:54:12.441704 14094 solver.cpp:228] Iteration 2650, loss = 0.394512
I0823 04:54:12.441818 14094 solver.cpp:245]     Train net output #0: loss = 0.394512 (* 1 = 0.394512 loss)
I0823 04:54:32.881182 14094 sgd_solver.cpp:106] Iteration 2650, lr = 0.0001
I0823 05:04:20.265236 14094 solver.cpp:228] Iteration 2700, loss = 0.431401
I0823 05:04:20.265342 14094 solver.cpp:245]     Train net output #0: loss = 0.431401 (* 1 = 0.431401 loss)
I0823 05:04:40.715975 14094 sgd_solver.cpp:106] Iteration 2700, lr = 0.0001
I0823 05:14:26.945829 14094 solver.cpp:228] Iteration 2750, loss = 0.460962
I0823 05:14:26.945950 14094 solver.cpp:245]     Train net output #0: loss = 0.460962 (* 1 = 0.460962 loss)
I0823 05:14:47.277225 14094 sgd_solver.cpp:106] Iteration 2750, lr = 0.0001
I0823 05:24:33.594571 14094 solver.cpp:228] Iteration 2800, loss = 0.390019
I0823 05:24:33.594681 14094 solver.cpp:245]     Train net output #0: loss = 0.390019 (* 1 = 0.390019 loss)
I0823 05:24:54.297147 14094 sgd_solver.cpp:106] Iteration 2800, lr = 0.0001
I0823 05:34:40.867254 14094 solver.cpp:228] Iteration 2850, loss = 0.316337
I0823 05:34:40.867380 14094 solver.cpp:245]     Train net output #0: loss = 0.316337 (* 1 = 0.316337 loss)
I0823 05:35:01.525408 14094 sgd_solver.cpp:106] Iteration 2850, lr = 0.0001
I0823 05:44:48.619231 14094 solver.cpp:228] Iteration 2900, loss = 0.509436
I0823 05:44:48.619344 14094 solver.cpp:245]     Train net output #0: loss = 0.509436 (* 1 = 0.509436 loss)
I0823 05:45:09.080281 14094 sgd_solver.cpp:106] Iteration 2900, lr = 0.0001
I0823 05:54:55.543972 14094 solver.cpp:228] Iteration 2950, loss = 0.262856
I0823 05:54:55.544080 14094 solver.cpp:245]     Train net output #0: loss = 0.262856 (* 1 = 0.262856 loss)
I0823 05:55:15.890363 14094 sgd_solver.cpp:106] Iteration 2950, lr = 0.0001
I0823 06:04:50.601456 14094 solver.cpp:338] Iteration 3000, Testing net (#0)
I0823 06:07:21.656699 14094 solver.cpp:406]     Test net output #0: loss = 0.376799 (* 1 = 0.376799 loss)
I0823 06:07:21.859954 14094 solver.cpp:406]     Test net output #1000000: prob = 4.19274e-07
I0823 06:07:22.062161 14094 solver.cpp:406]     Test net output #2000000: prob = 1.53347e-06
I0823 06:07:22.264026 14094 solver.cpp:406]     Test net output #3000000: prob = 3.00337e-08
I0823 06:07:22.466003 14094 solver.cpp:406]     Test net output #4000000: prob = 2.0968e-07
I0823 06:07:22.668553 14094 solver.cpp:406]     Test net output #5000000: prob = 1.47864e-07
I0823 06:07:22.871237 14094 solver.cpp:406]     Test net output #6000000: prob = 2.98834e-07
I0823 06:07:23.073251 14094 solver.cpp:406]     Test net output #7000000: prob = 5.06446e-06
I0823 06:07:23.275174 14094 solver.cpp:406]     Test net output #8000000: prob = 1.48551e-05
I0823 06:07:23.477802 14094 solver.cpp:406]     Test net output #9000000: prob = 4.15554e-08
I0823 06:07:23.679749 14094 solver.cpp:406]     Test net output #10000000: prob = 2.36221e-07
I0823 06:07:23.882133 14094 solver.cpp:406]     Test net output #11000000: prob = 2.35156e-07
I0823 06:07:24.084720 14094 solver.cpp:406]     Test net output #12000000: prob = 4.59093e-07
I0823 06:07:24.287145 14094 solver.cpp:406]     Test net output #13000000: prob = 7.43926e-07
I0823 06:07:24.490031 14094 solver.cpp:406]     Test net output #14000000: prob = 6.52727e-07
I0823 06:07:24.691918 14094 solver.cpp:406]     Test net output #15000000: prob = 9.25409e-08
I0823 06:07:24.894901 14094 solver.cpp:406]     Test net output #16000000: prob = 4.93745e-07
I0823 06:07:25.096933 14094 solver.cpp:406]     Test net output #17000000: prob = 4.78767e-07
I0823 06:07:25.569180 14094 solver.cpp:228] Iteration 3000, loss = 0.314001
I0823 06:07:25.569206 14094 solver.cpp:245]     Train net output #0: loss = 0.314001 (* 1 = 0.314001 loss)
I0823 06:07:45.600605 14094 sgd_solver.cpp:106] Iteration 3000, lr = 0.0001
I0823 06:17:28.858117 14094 solver.cpp:228] Iteration 3050, loss = 0.3585
I0823 06:17:28.858227 14094 solver.cpp:245]     Train net output #0: loss = 0.3585 (* 1 = 0.3585 loss)
I0823 06:17:49.514166 14094 sgd_solver.cpp:106] Iteration 3050, lr = 0.0001
I0823 06:27:36.389684 14094 solver.cpp:228] Iteration 3100, loss = 0.263521
I0823 06:27:36.390478 14094 solver.cpp:245]     Train net output #0: loss = 0.263521 (* 1 = 0.263521 loss)
I0823 06:27:56.740278 14094 sgd_solver.cpp:106] Iteration 3100, lr = 0.0001
I0823 06:37:43.107915 14094 solver.cpp:228] Iteration 3150, loss = 0.266904
I0823 06:37:43.108009 14094 solver.cpp:245]     Train net output #0: loss = 0.266904 (* 1 = 0.266904 loss)
I0823 06:38:03.778442 14094 sgd_solver.cpp:106] Iteration 3150, lr = 0.0001
I0823 06:47:50.643999 14094 solver.cpp:228] Iteration 3200, loss = 0.355052
I0823 06:47:50.644114 14094 solver.cpp:245]     Train net output #0: loss = 0.355052 (* 1 = 0.355052 loss)
I0823 06:48:11.515501 14094 sgd_solver.cpp:106] Iteration 3200, lr = 0.0001
I0823 06:57:59.716857 14094 solver.cpp:228] Iteration 3250, loss = 0.441409
I0823 06:57:59.716914 14094 solver.cpp:245]     Train net output #0: loss = 0.441409 (* 1 = 0.441409 loss)
I0823 06:58:20.547319 14094 sgd_solver.cpp:106] Iteration 3250, lr = 0.0001
I0823 07:08:07.213253 14094 solver.cpp:228] Iteration 3300, loss = 0.350516
I0823 07:08:07.213382 14094 solver.cpp:245]     Train net output #0: loss = 0.350516 (* 1 = 0.350516 loss)
I0823 07:08:27.745643 14094 sgd_solver.cpp:106] Iteration 3300, lr = 0.0001
I0823 07:18:14.735908 14094 solver.cpp:228] Iteration 3350, loss = 0.583341
I0823 07:18:14.736845 14094 solver.cpp:245]     Train net output #0: loss = 0.583341 (* 1 = 0.583341 loss)
I0823 07:18:35.051729 14094 sgd_solver.cpp:106] Iteration 3350, lr = 0.0001
I0823 07:28:22.257346 14094 solver.cpp:228] Iteration 3400, loss = 0.383486
I0823 07:28:22.258219 14094 solver.cpp:245]     Train net output #0: loss = 0.383486 (* 1 = 0.383486 loss)
I0823 07:28:43.262516 14094 sgd_solver.cpp:106] Iteration 3400, lr = 0.0001
I0823 07:38:31.629111 14094 solver.cpp:228] Iteration 3450, loss = 0.37342
I0823 07:38:31.629218 14094 solver.cpp:245]     Train net output #0: loss = 0.37342 (* 1 = 0.37342 loss)
I0823 07:38:52.347753 14094 sgd_solver.cpp:106] Iteration 3450, lr = 0.0001
I0823 07:48:39.644578 14094 solver.cpp:228] Iteration 3500, loss = 0.397965
I0823 07:48:39.644666 14094 solver.cpp:245]     Train net output #0: loss = 0.397965 (* 1 = 0.397965 loss)
I0823 07:49:00.013123 14094 sgd_solver.cpp:106] Iteration 3500, lr = 0.0001
I0823 07:58:47.444906 14094 solver.cpp:228] Iteration 3550, loss = 0.409327
I0823 07:58:47.445000 14094 solver.cpp:245]     Train net output #0: loss = 0.409327 (* 1 = 0.409327 loss)
I0823 07:59:07.815948 14094 sgd_solver.cpp:106] Iteration 3550, lr = 0.0001
I0823 08:08:49.425367 14094 solver.cpp:228] Iteration 3600, loss = 0.474964
I0823 08:08:49.425446 14094 solver.cpp:245]     Train net output #0: loss = 0.474964 (* 1 = 0.474964 loss)
I0823 08:09:10.027936 14094 sgd_solver.cpp:106] Iteration 3600, lr = 0.0001
I0823 08:18:50.376565 14094 solver.cpp:228] Iteration 3650, loss = 0.419671
I0823 08:18:50.376675 14094 solver.cpp:245]     Train net output #0: loss = 0.419671 (* 1 = 0.419671 loss)
I0823 08:19:11.139894 14094 sgd_solver.cpp:106] Iteration 3650, lr = 0.0001
I0823 08:28:50.052907 14094 solver.cpp:228] Iteration 3700, loss = 0.462256
I0823 08:28:50.052947 14094 solver.cpp:245]     Train net output #0: loss = 0.462256 (* 1 = 0.462256 loss)
I0823 08:29:10.224313 14094 sgd_solver.cpp:106] Iteration 3700, lr = 0.0001
I0823 08:38:47.526770 14094 solver.cpp:228] Iteration 3750, loss = 0.29641
I0823 08:38:47.527715 14094 solver.cpp:245]     Train net output #0: loss = 0.29641 (* 1 = 0.29641 loss)
I0823 08:39:08.142041 14094 sgd_solver.cpp:106] Iteration 3750, lr = 0.0001
I0823 08:48:45.499744 14094 solver.cpp:228] Iteration 3800, loss = 0.450661
I0823 08:48:45.499840 14094 solver.cpp:245]     Train net output #0: loss = 0.450661 (* 1 = 0.450661 loss)
I0823 08:49:05.679951 14094 sgd_solver.cpp:106] Iteration 3800, lr = 0.0001
I0823 08:58:42.905380 14094 solver.cpp:228] Iteration 3850, loss = 0.256671
I0823 08:58:42.906437 14094 solver.cpp:245]     Train net output #0: loss = 0.256671 (* 1 = 0.256671 loss)
I0823 08:59:03.565760 14094 sgd_solver.cpp:106] Iteration 3850, lr = 0.0001
I0823 09:08:40.028162 14094 solver.cpp:228] Iteration 3900, loss = 0.37543
I0823 09:08:40.028211 14094 solver.cpp:245]     Train net output #0: loss = 0.37543 (* 1 = 0.37543 loss)
I0823 09:09:00.390970 14094 sgd_solver.cpp:106] Iteration 3900, lr = 0.0001
I0823 09:18:36.413126 14094 solver.cpp:228] Iteration 3950, loss = 0.434846
I0823 09:18:36.413235 14094 solver.cpp:245]     Train net output #0: loss = 0.434846 (* 1 = 0.434846 loss)
I0823 09:18:56.746800 14094 sgd_solver.cpp:106] Iteration 3950, lr = 0.0001
I0823 09:28:21.472076 14094 solver.cpp:456] Snapshotting to binary proto file examples/jr-station/vgg_iter_4000.caffemodel
I0823 09:29:06.779450 14094 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/jr-station/vgg_iter_4000.solverstate
I0823 09:29:13.742399 14094 solver.cpp:338] Iteration 4000, Testing net (#0)
I0823 09:29:14.632275 14133 blocking_queue.cpp:50] Waiting for data
I0823 09:29:15.122011 14094 blocking_queue.cpp:50] Data layer prefetch queue empty
I0823 09:31:32.902592 14094 solver.cpp:406]     Test net output #0: loss = 0.367492 (* 1 = 0.367492 loss)
I0823 09:31:33.104738 14094 solver.cpp:406]     Test net output #1000000: prob = 3.93578e-07
I0823 09:31:33.306797 14094 solver.cpp:406]     Test net output #2000000: prob = 2.06377e-06
I0823 09:31:33.508960 14094 solver.cpp:406]     Test net output #3000000: prob = 2.95996e-08
I0823 09:31:33.711735 14094 solver.cpp:406]     Test net output #4000000: prob = 1.07949e-07
I0823 09:31:33.913595 14094 solver.cpp:406]     Test net output #5000000: prob = 1.01546e-07
I0823 09:31:34.115547 14094 solver.cpp:406]     Test net output #6000000: prob = 7.39124e-08
I0823 09:31:34.317657 14094 solver.cpp:406]     Test net output #7000000: prob = 4.62246e-06
I0823 09:31:34.520206 14094 solver.cpp:406]     Test net output #8000000: prob = 1.44959e-05
I0823 09:31:34.722789 14094 solver.cpp:406]     Test net output #9000000: prob = 4.35478e-08
I0823 09:31:34.924711 14094 solver.cpp:406]     Test net output #10000000: prob = 2.08282e-07
I0823 09:31:35.127218 14094 solver.cpp:406]     Test net output #11000000: prob = 2.14321e-07
I0823 09:31:35.329216 14094 solver.cpp:406]     Test net output #12000000: prob = 4.9972e-07
I0823 09:31:35.531481 14094 solver.cpp:406]     Test net output #13000000: prob = 2.67596e-07
I0823 09:31:35.734607 14094 solver.cpp:406]     Test net output #14000000: prob = 5.89327e-07
I0823 09:31:35.937113 14094 solver.cpp:406]     Test net output #15000000: prob = 7.82929e-08
I0823 09:31:36.138983 14094 solver.cpp:406]     Test net output #16000000: prob = 4.49084e-07
I0823 09:31:36.341497 14094 solver.cpp:406]     Test net output #17000000: prob = 4.36704e-07
I0823 09:31:36.803902 14094 solver.cpp:228] Iteration 4000, loss = 0.486953
I0823 09:31:36.803928 14094 solver.cpp:245]     Train net output #0: loss = 0.486953 (* 1 = 0.486953 loss)
I0823 09:31:56.827500 14094 sgd_solver.cpp:106] Iteration 4000, lr = 1e-05
I0823 09:41:33.861928 14094 solver.cpp:228] Iteration 4050, loss = 0.443179
I0823 09:41:33.862043 14094 solver.cpp:245]     Train net output #0: loss = 0.443179 (* 1 = 0.443179 loss)
I0823 09:41:54.118446 14094 sgd_solver.cpp:106] Iteration 4050, lr = 1e-05
I0823 09:51:30.702458 14094 solver.cpp:228] Iteration 4100, loss = 0.311571
I0823 09:51:30.702534 14094 solver.cpp:245]     Train net output #0: loss = 0.311571 (* 1 = 0.311571 loss)
I0823 09:51:51.124281 14094 sgd_solver.cpp:106] Iteration 4100, lr = 1e-05
I0823 10:01:26.962177 14094 solver.cpp:228] Iteration 4150, loss = 0.371268
I0823 10:01:26.962216 14094 solver.cpp:245]     Train net output #0: loss = 0.371268 (* 1 = 0.371268 loss)
I0823 10:01:47.082733 14094 sgd_solver.cpp:106] Iteration 4150, lr = 1e-05
I0823 10:11:23.133599 14094 solver.cpp:228] Iteration 4200, loss = 0.346523
I0823 10:11:23.133703 14094 solver.cpp:245]     Train net output #0: loss = 0.346523 (* 1 = 0.346523 loss)
I0823 10:11:43.386843 14094 sgd_solver.cpp:106] Iteration 4200, lr = 1e-05
I0823 10:21:19.733911 14094 solver.cpp:228] Iteration 4250, loss = 0.252502
I0823 10:21:19.734002 14094 solver.cpp:245]     Train net output #0: loss = 0.252502 (* 1 = 0.252502 loss)
I0823 10:21:39.949687 14094 sgd_solver.cpp:106] Iteration 4250, lr = 1e-05
I0823 10:31:14.476333 14094 solver.cpp:228] Iteration 4300, loss = 0.304764
I0823 10:31:14.476408 14094 solver.cpp:245]     Train net output #0: loss = 0.304764 (* 1 = 0.304764 loss)
I0823 10:31:34.542711 14094 sgd_solver.cpp:106] Iteration 4300, lr = 1e-05
I0823 10:41:07.619253 14094 solver.cpp:228] Iteration 4350, loss = 0.499385
I0823 10:41:07.619341 14094 solver.cpp:245]     Train net output #0: loss = 0.499385 (* 1 = 0.499385 loss)
I0823 10:41:27.725945 14094 sgd_solver.cpp:106] Iteration 4350, lr = 1e-05
I0823 10:51:00.493335 14094 solver.cpp:228] Iteration 4400, loss = 0.378692
I0823 10:51:00.493444 14094 solver.cpp:245]     Train net output #0: loss = 0.378692 (* 1 = 0.378692 loss)
I0823 10:51:20.560669 14094 sgd_solver.cpp:106] Iteration 4400, lr = 1e-05
I0823 11:00:53.981412 14094 solver.cpp:228] Iteration 4450, loss = 0.409416
I0823 11:00:53.981489 14094 solver.cpp:245]     Train net output #0: loss = 0.409416 (* 1 = 0.409416 loss)
I0823 11:01:14.109863 14094 sgd_solver.cpp:106] Iteration 4450, lr = 1e-05
I0823 11:10:50.349738 14094 solver.cpp:228] Iteration 4500, loss = 0.302319
I0823 11:10:50.349858 14094 solver.cpp:245]     Train net output #0: loss = 0.302319 (* 1 = 0.302319 loss)
I0823 11:11:10.603843 14094 sgd_solver.cpp:106] Iteration 4500, lr = 1e-05
I0823 11:20:46.230496 14094 solver.cpp:228] Iteration 4550, loss = 0.217231
I0823 11:20:46.230584 14094 solver.cpp:245]     Train net output #0: loss = 0.217231 (* 1 = 0.217231 loss)
I0823 11:21:06.277015 14094 sgd_solver.cpp:106] Iteration 4550, lr = 1e-05
I0823 11:30:40.723570 14094 solver.cpp:228] Iteration 4600, loss = 0.364385
I0823 11:30:40.724349 14094 solver.cpp:245]     Train net output #0: loss = 0.364385 (* 1 = 0.364385 loss)
I0823 11:31:01.668148 14094 sgd_solver.cpp:106] Iteration 4600, lr = 1e-05
I0823 11:40:47.750250 14094 solver.cpp:228] Iteration 4650, loss = 0.274177
I0823 11:40:47.750321 14094 solver.cpp:245]     Train net output #0: loss = 0.274177 (* 1 = 0.274177 loss)
I0823 11:41:08.544384 14094 sgd_solver.cpp:106] Iteration 4650, lr = 1e-05
I0823 11:50:43.701849 14094 solver.cpp:228] Iteration 4700, loss = 0.314829
I0823 11:50:43.702432 14094 solver.cpp:245]     Train net output #0: loss = 0.314829 (* 1 = 0.314829 loss)
I0823 11:51:15.452736 14094 sgd_solver.cpp:106] Iteration 4700, lr = 1e-05
I0823 12:00:59.454087 14094 solver.cpp:228] Iteration 4750, loss = 0.235781
I0823 12:00:59.454192 14094 solver.cpp:245]     Train net output #0: loss = 0.235781 (* 1 = 0.235781 loss)
I0823 12:01:31.794637 14094 sgd_solver.cpp:106] Iteration 4750, lr = 1e-05
I0823 12:11:28.219235 14094 solver.cpp:228] Iteration 4800, loss = 0.305297
I0823 12:11:28.219339 14094 solver.cpp:245]     Train net output #0: loss = 0.305297 (* 1 = 0.305297 loss)
I0823 12:12:00.581637 14094 sgd_solver.cpp:106] Iteration 4800, lr = 1e-05
I0823 12:21:53.119603 14094 solver.cpp:228] Iteration 4850, loss = 0.313284
I0823 12:21:53.119709 14094 solver.cpp:245]     Train net output #0: loss = 0.313284 (* 1 = 0.313284 loss)
I0823 12:22:27.206225 14094 sgd_solver.cpp:106] Iteration 4850, lr = 1e-05
I0823 12:32:16.407650 14094 solver.cpp:228] Iteration 4900, loss = 0.376363
I0823 12:32:16.407748 14094 solver.cpp:245]     Train net output #0: loss = 0.376363 (* 1 = 0.376363 loss)
I0823 12:32:50.232182 14094 sgd_solver.cpp:106] Iteration 4900, lr = 1e-05
I0823 12:42:37.701691 14094 solver.cpp:228] Iteration 4950, loss = 0.333632
I0823 12:42:37.701822 14094 solver.cpp:245]     Train net output #0: loss = 0.333632 (* 1 = 0.333632 loss)
I0823 12:43:11.871621 14094 sgd_solver.cpp:106] Iteration 4950, lr = 1e-05
I0823 12:52:52.292747 14094 solver.cpp:338] Iteration 5000, Testing net (#0)
I0823 12:55:25.120642 14094 solver.cpp:406]     Test net output #0: loss = 0.370546 (* 1 = 0.370546 loss)
I0823 12:55:25.354102 14094 solver.cpp:406]     Test net output #1000000: prob = 1.85363e-07
I0823 12:55:25.583654 14094 solver.cpp:406]     Test net output #2000000: prob = 1.42823e-06
I0823 12:55:25.791724 14094 solver.cpp:406]     Test net output #3000000: prob = 2.41942e-08
I0823 12:55:25.996497 14094 solver.cpp:406]     Test net output #4000000: prob = 2.04186e-07
I0823 12:55:26.201414 14094 solver.cpp:406]     Test net output #5000000: prob = 1.07113e-07
I0823 12:55:26.404542 14094 solver.cpp:406]     Test net output #6000000: prob = 3.07425e-07
I0823 12:55:26.607383 14094 solver.cpp:406]     Test net output #7000000: prob = 5.14102e-06
I0823 12:55:26.810073 14094 solver.cpp:406]     Test net output #8000000: prob = 1.56788e-05
I0823 12:55:27.013034 14094 solver.cpp:406]     Test net output #9000000: prob = 2.92298e-08
I0823 12:55:27.215723 14094 solver.cpp:406]     Test net output #10000000: prob = 1.84996e-07
I0823 12:55:27.420580 14094 solver.cpp:406]     Test net output #11000000: prob = 2.64936e-07
I0823 12:55:27.625046 14094 solver.cpp:406]     Test net output #12000000: prob = 5.83564e-07
I0823 12:55:27.829159 14094 solver.cpp:406]     Test net output #13000000: prob = 5.55549e-07
I0823 12:55:28.033926 14094 solver.cpp:406]     Test net output #14000000: prob = 6.52669e-07
I0823 12:55:28.238306 14094 solver.cpp:406]     Test net output #15000000: prob = 5.91547e-08
I0823 12:55:28.442292 14094 solver.cpp:406]     Test net output #16000000: prob = 1.95927e-07
I0823 12:55:28.646301 14094 solver.cpp:406]     Test net output #17000000: prob = 2.07706e-07
I0823 12:55:29.107784 14094 solver.cpp:228] Iteration 5000, loss = 0.314057
I0823 12:55:29.107807 14094 solver.cpp:245]     Train net output #0: loss = 0.314057 (* 1 = 0.314057 loss)
I0823 12:55:50.922726 14094 sgd_solver.cpp:106] Iteration 5000, lr = 1e-05
I0823 13:05:38.820678 14094 solver.cpp:228] Iteration 5050, loss = 0.391502
I0823 13:05:38.820756 14094 solver.cpp:245]     Train net output #0: loss = 0.391502 (* 1 = 0.391502 loss)
I0823 13:05:59.674078 14094 sgd_solver.cpp:106] Iteration 5050, lr = 1e-05
I0823 13:15:47.080572 14094 solver.cpp:228] Iteration 5100, loss = 0.423389
I0823 13:15:47.080624 14094 solver.cpp:245]     Train net output #0: loss = 0.423388 (* 1 = 0.423388 loss)
I0823 13:16:07.942013 14094 sgd_solver.cpp:106] Iteration 5100, lr = 1e-05
I0823 13:25:55.012903 14094 solver.cpp:228] Iteration 5150, loss = 0.528371
I0823 13:25:55.012977 14094 solver.cpp:245]     Train net output #0: loss = 0.52837 (* 1 = 0.52837 loss)
I0823 13:26:16.080972 14094 sgd_solver.cpp:106] Iteration 5150, lr = 1e-05
I0823 13:36:04.835639 14094 solver.cpp:228] Iteration 5200, loss = 0.287258
I0823 13:36:04.836374 14094 solver.cpp:245]     Train net output #0: loss = 0.287258 (* 1 = 0.287258 loss)
I0823 13:36:25.794710 14094 sgd_solver.cpp:106] Iteration 5200, lr = 1e-05
I0823 13:46:17.227056 14094 solver.cpp:228] Iteration 5250, loss = 0.348999
I0823 13:46:17.227167 14094 solver.cpp:245]     Train net output #0: loss = 0.348999 (* 1 = 0.348999 loss)
I0823 13:46:38.227183 14094 sgd_solver.cpp:106] Iteration 5250, lr = 1e-05
I0823 13:56:35.484890 14094 solver.cpp:228] Iteration 5300, loss = 0.338473
I0823 13:56:35.484962 14094 solver.cpp:245]     Train net output #0: loss = 0.338473 (* 1 = 0.338473 loss)
I0823 13:56:56.536103 14094 sgd_solver.cpp:106] Iteration 5300, lr = 1e-05
I0823 14:06:37.821841 14094 solver.cpp:228] Iteration 5350, loss = 0.380607
I0823 14:06:37.821949 14094 solver.cpp:245]     Train net output #0: loss = 0.380607 (* 1 = 0.380607 loss)
I0823 14:06:58.866276 14094 sgd_solver.cpp:106] Iteration 5350, lr = 1e-05
I0823 14:16:43.918645 14094 solver.cpp:228] Iteration 5400, loss = 0.354809
I0823 14:16:43.918745 14094 solver.cpp:245]     Train net output #0: loss = 0.354808 (* 1 = 0.354808 loss)
I0823 14:17:04.162892 14094 sgd_solver.cpp:106] Iteration 5400, lr = 1e-05
I0823 14:26:39.871369 14094 solver.cpp:228] Iteration 5450, loss = 0.205173
I0823 14:26:39.871459 14094 solver.cpp:245]     Train net output #0: loss = 0.205173 (* 1 = 0.205173 loss)
I0823 14:27:00.005311 14094 sgd_solver.cpp:106] Iteration 5450, lr = 1e-05
I0823 14:36:35.647202 14094 solver.cpp:228] Iteration 5500, loss = 0.345654
I0823 14:36:35.647308 14094 solver.cpp:245]     Train net output #0: loss = 0.345653 (* 1 = 0.345653 loss)
I0823 14:36:55.656574 14094 sgd_solver.cpp:106] Iteration 5500, lr = 1e-05
I0823 14:46:28.846078 14094 solver.cpp:228] Iteration 5550, loss = 0.237296
I0823 14:46:28.846189 14094 solver.cpp:245]     Train net output #0: loss = 0.237296 (* 1 = 0.237296 loss)
I0823 14:46:48.947290 14094 sgd_solver.cpp:106] Iteration 5550, lr = 1e-05
I0823 14:56:19.600311 14094 solver.cpp:228] Iteration 5600, loss = 0.298509
I0823 14:56:19.600411 14094 solver.cpp:245]     Train net output #0: loss = 0.298509 (* 1 = 0.298509 loss)
I0823 14:56:39.859361 14094 sgd_solver.cpp:106] Iteration 5600, lr = 1e-05
I0823 15:06:13.331804 14094 solver.cpp:228] Iteration 5650, loss = 0.269618
I0823 15:06:13.332217 14094 solver.cpp:245]     Train net output #0: loss = 0.269618 (* 1 = 0.269618 loss)
I0823 15:06:34.806576 14094 sgd_solver.cpp:106] Iteration 5650, lr = 1e-05
I0823 15:16:10.814244 14094 solver.cpp:228] Iteration 5700, loss = 0.43634
I0823 15:16:10.814363 14094 solver.cpp:245]     Train net output #0: loss = 0.43634 (* 1 = 0.43634 loss)
I0823 15:16:31.208073 14094 sgd_solver.cpp:106] Iteration 5700, lr = 1e-05
I0823 15:26:15.928902 14094 solver.cpp:228] Iteration 5750, loss = 0.370418
I0823 15:26:15.928985 14094 solver.cpp:245]     Train net output #0: loss = 0.370418 (* 1 = 0.370418 loss)
I0823 15:26:36.501484 14094 sgd_solver.cpp:106] Iteration 5750, lr = 1e-05
I0823 15:36:14.655515 14094 solver.cpp:228] Iteration 5800, loss = 0.274428
I0823 15:36:14.655632 14094 solver.cpp:245]     Train net output #0: loss = 0.274428 (* 1 = 0.274428 loss)
I0823 15:36:36.028403 14094 sgd_solver.cpp:106] Iteration 5800, lr = 1e-05
I0823 15:46:16.531148 14094 solver.cpp:228] Iteration 5850, loss = 0.251469
I0823 15:46:16.531201 14094 solver.cpp:245]     Train net output #0: loss = 0.251468 (* 1 = 0.251468 loss)
I0823 15:46:37.228931 14094 sgd_solver.cpp:106] Iteration 5850, lr = 1e-05
I0823 15:56:17.045024 14094 solver.cpp:228] Iteration 5900, loss = 0.243845
I0823 15:56:17.045116 14094 solver.cpp:245]     Train net output #0: loss = 0.243844 (* 1 = 0.243844 loss)
I0823 15:56:37.816404 14094 sgd_solver.cpp:106] Iteration 5900, lr = 1e-05
I0823 16:06:19.189043 14094 solver.cpp:228] Iteration 5950, loss = 0.18833
I0823 16:06:19.189146 14094 solver.cpp:245]     Train net output #0: loss = 0.18833 (* 1 = 0.18833 loss)
I0823 16:06:39.653244 14094 sgd_solver.cpp:106] Iteration 5950, lr = 1e-05
I0823 16:16:04.891450 14094 solver.cpp:338] Iteration 6000, Testing net (#0)
I0823 16:18:37.573989 14094 solver.cpp:406]     Test net output #0: loss = 0.372463 (* 1 = 0.372463 loss)
I0823 16:18:37.803557 14094 solver.cpp:406]     Test net output #1000000: prob = 2.86939e-07
I0823 16:18:38.033567 14094 solver.cpp:406]     Test net output #2000000: prob = 2.21883e-07
I0823 16:18:38.263701 14094 solver.cpp:406]     Test net output #3000000: prob = 1.09506e-08
I0823 16:18:38.493487 14094 solver.cpp:406]     Test net output #4000000: prob = 1.48884e-07
I0823 16:18:38.757364 14094 solver.cpp:406]     Test net output #5000000: prob = 1.14189e-07
I0823 16:18:39.013240 14094 solver.cpp:406]     Test net output #6000000: prob = 3.041e-07
I0823 16:18:39.243389 14094 solver.cpp:406]     Test net output #7000000: prob = 2.49469e-07
I0823 16:18:39.474928 14094 solver.cpp:406]     Test net output #8000000: prob = 7.2873e-07
I0823 16:18:39.681087 14094 solver.cpp:406]     Test net output #9000000: prob = 2.12852e-08
I0823 16:18:39.883147 14094 solver.cpp:406]     Test net output #10000000: prob = 1.48146e-07
I0823 16:18:40.085119 14094 solver.cpp:406]     Test net output #11000000: prob = 2.12477e-07
I0823 16:18:40.287037 14094 solver.cpp:406]     Test net output #12000000: prob = 5.0858e-07
I0823 16:18:40.489223 14094 solver.cpp:406]     Test net output #13000000: prob = 3.31618e-07
I0823 16:18:40.700007 14094 solver.cpp:406]     Test net output #14000000: prob = 1.4185e-07
I0823 16:18:40.930371 14094 solver.cpp:406]     Test net output #15000000: prob = 4.86789e-08
I0823 16:18:41.159744 14094 solver.cpp:406]     Test net output #16000000: prob = 2.9559e-07
I0823 16:18:41.389432 14094 solver.cpp:406]     Test net output #17000000: prob = 3.15987e-07
I0823 16:18:41.885781 14094 solver.cpp:228] Iteration 6000, loss = 0.298746
I0823 16:18:41.885807 14094 solver.cpp:245]     Train net output #0: loss = 0.298746 (* 1 = 0.298746 loss)
I0823 16:19:02.541879 14094 sgd_solver.cpp:106] Iteration 6000, lr = 1e-06
I0823 16:28:39.589275 14094 solver.cpp:228] Iteration 6050, loss = 0.335612
I0823 16:28:39.589324 14094 solver.cpp:245]     Train net output #0: loss = 0.335612 (* 1 = 0.335612 loss)
I0823 16:29:00.254300 14094 sgd_solver.cpp:106] Iteration 6050, lr = 1e-06
I0823 16:38:36.614446 14094 solver.cpp:228] Iteration 6100, loss = 0.289633
I0823 16:38:36.614517 14094 solver.cpp:245]     Train net output #0: loss = 0.289633 (* 1 = 0.289633 loss)
I0823 16:38:57.480165 14094 sgd_solver.cpp:106] Iteration 6100, lr = 1e-06
I0823 16:48:34.113287 14094 solver.cpp:228] Iteration 6150, loss = 0.403534
I0823 16:48:34.113358 14094 solver.cpp:245]     Train net output #0: loss = 0.403534 (* 1 = 0.403534 loss)
I0823 16:48:54.698079 14094 sgd_solver.cpp:106] Iteration 6150, lr = 1e-06
I0823 16:58:30.784739 14094 solver.cpp:228] Iteration 6200, loss = 0.358609
I0823 16:58:30.784854 14094 solver.cpp:245]     Train net output #0: loss = 0.358609 (* 1 = 0.358609 loss)
I0823 16:58:51.328007 14094 sgd_solver.cpp:106] Iteration 6200, lr = 1e-06
I0823 17:08:29.230509 14094 solver.cpp:228] Iteration 6250, loss = 0.291857
I0823 17:08:29.230568 14094 solver.cpp:245]     Train net output #0: loss = 0.291857 (* 1 = 0.291857 loss)
I0823 17:08:50.087811 14094 sgd_solver.cpp:106] Iteration 6250, lr = 1e-06
I0823 17:18:26.767613 14094 solver.cpp:228] Iteration 6300, loss = 0.280279
I0823 17:18:26.767704 14094 solver.cpp:245]     Train net output #0: loss = 0.280279 (* 1 = 0.280279 loss)
I0823 17:18:47.206578 14094 sgd_solver.cpp:106] Iteration 6300, lr = 1e-06
I0823 17:28:18.344373 14094 solver.cpp:228] Iteration 6350, loss = 0.288567
I0823 17:28:18.344442 14094 solver.cpp:245]     Train net output #0: loss = 0.288566 (* 1 = 0.288566 loss)
I0823 17:28:38.361456 14094 sgd_solver.cpp:106] Iteration 6350, lr = 1e-06
I0823 17:38:08.212281 14094 solver.cpp:228] Iteration 6400, loss = 0.377273
I0823 17:38:08.212327 14094 solver.cpp:245]     Train net output #0: loss = 0.377273 (* 1 = 0.377273 loss)
I0823 17:38:28.222569 14094 sgd_solver.cpp:106] Iteration 6400, lr = 1e-06
I0823 17:47:56.930970 14094 solver.cpp:228] Iteration 6450, loss = 0.394913
I0823 17:47:56.931043 14094 solver.cpp:245]     Train net output #0: loss = 0.394913 (* 1 = 0.394913 loss)
I0823 17:48:17.035182 14094 sgd_solver.cpp:106] Iteration 6450, lr = 1e-06
I0823 17:57:42.344724 14094 solver.cpp:228] Iteration 6500, loss = 0.382657
I0823 17:57:42.344796 14094 solver.cpp:245]     Train net output #0: loss = 0.382657 (* 1 = 0.382657 loss)
I0823 17:58:02.438643 14094 sgd_solver.cpp:106] Iteration 6500, lr = 1e-06
I0823 18:07:31.661805 14094 solver.cpp:228] Iteration 6550, loss = 0.33475
I0823 18:07:31.661902 14094 solver.cpp:245]     Train net output #0: loss = 0.33475 (* 1 = 0.33475 loss)
I0823 18:07:51.571256 14094 sgd_solver.cpp:106] Iteration 6550, lr = 1e-06
I0823 18:17:20.876693 14094 solver.cpp:228] Iteration 6600, loss = 0.272154
I0823 18:17:20.876762 14094 solver.cpp:245]     Train net output #0: loss = 0.272153 (* 1 = 0.272153 loss)
I0823 18:17:40.909564 14094 sgd_solver.cpp:106] Iteration 6600, lr = 1e-06
I0823 18:27:10.323559 14094 solver.cpp:228] Iteration 6650, loss = 0.364198
I0823 18:27:10.323663 14094 solver.cpp:245]     Train net output #0: loss = 0.364198 (* 1 = 0.364198 loss)
I0823 18:27:30.324259 14094 sgd_solver.cpp:106] Iteration 6650, lr = 1e-06
I0823 18:36:59.895442 14094 solver.cpp:228] Iteration 6700, loss = 0.405864
I0823 18:36:59.895546 14094 solver.cpp:245]     Train net output #0: loss = 0.405864 (* 1 = 0.405864 loss)
I0823 18:37:19.898357 14094 sgd_solver.cpp:106] Iteration 6700, lr = 1e-06
I0823 18:46:49.909279 14094 solver.cpp:228] Iteration 6750, loss = 0.422968
I0823 18:46:49.909387 14094 solver.cpp:245]     Train net output #0: loss = 0.422967 (* 1 = 0.422967 loss)
I0823 18:47:10.021555 14094 sgd_solver.cpp:106] Iteration 6750, lr = 1e-06
I0823 18:56:39.185189 14094 solver.cpp:228] Iteration 6800, loss = 0.372492
I0823 18:56:39.185235 14094 solver.cpp:245]     Train net output #0: loss = 0.372492 (* 1 = 0.372492 loss)
I0823 18:56:59.234336 14094 sgd_solver.cpp:106] Iteration 6800, lr = 1e-06
I0823 19:06:28.571403 14094 solver.cpp:228] Iteration 6850, loss = 0.295497
I0823 19:06:28.571508 14094 solver.cpp:245]     Train net output #0: loss = 0.295497 (* 1 = 0.295497 loss)
I0823 19:06:48.557790 14094 sgd_solver.cpp:106] Iteration 6850, lr = 1e-06
I0823 19:16:17.621597 14094 solver.cpp:228] Iteration 6900, loss = 0.476288
I0823 19:16:17.621666 14094 solver.cpp:245]     Train net output #0: loss = 0.476288 (* 1 = 0.476288 loss)
I0823 19:16:37.622767 14094 sgd_solver.cpp:106] Iteration 6900, lr = 1e-06
I0823 19:26:06.811111 14094 solver.cpp:228] Iteration 6950, loss = 0.240453
I0823 19:26:06.811228 14094 solver.cpp:245]     Train net output #0: loss = 0.240452 (* 1 = 0.240452 loss)
I0823 19:26:26.849015 14094 sgd_solver.cpp:106] Iteration 6950, lr = 1e-06
I0823 19:35:45.633774 14094 solver.cpp:338] Iteration 7000, Testing net (#0)
I0823 19:38:14.769337 14094 solver.cpp:406]     Test net output #0: loss = 0.370282 (* 1 = 0.370282 loss)
I0823 19:38:14.971237 14094 solver.cpp:406]     Test net output #1000000: prob = 3.47963e-07
I0823 19:38:15.172992 14094 solver.cpp:406]     Test net output #2000000: prob = 1.29076e-06
I0823 19:38:15.374801 14094 solver.cpp:406]     Test net output #3000000: prob = 2.14649e-08
I0823 19:38:15.576601 14094 solver.cpp:406]     Test net output #4000000: prob = 1.92516e-07
I0823 19:38:15.778645 14094 solver.cpp:406]     Test net output #5000000: prob = 1.16798e-07
I0823 19:38:15.980743 14094 solver.cpp:406]     Test net output #6000000: prob = 3.09743e-07
I0823 19:38:16.182731 14094 solver.cpp:406]     Test net output #7000000: prob = 5.50454e-06
I0823 19:38:16.384722 14094 solver.cpp:406]     Test net output #8000000: prob = 1.64498e-05
I0823 19:38:16.586633 14094 solver.cpp:406]     Test net output #9000000: prob = 2.61741e-08
I0823 19:38:16.788453 14094 solver.cpp:406]     Test net output #10000000: prob = 1.77993e-07
I0823 19:38:16.990432 14094 solver.cpp:406]     Test net output #11000000: prob = 1.81793e-07
I0823 19:38:17.192457 14094 solver.cpp:406]     Test net output #12000000: prob = 3.47704e-07
I0823 19:38:17.394345 14094 solver.cpp:406]     Test net output #13000000: prob = 5.59266e-07
I0823 19:38:17.596068 14094 solver.cpp:406]     Test net output #14000000: prob = 6.03523e-07
I0823 19:38:17.797875 14094 solver.cpp:406]     Test net output #15000000: prob = 7.56306e-08
I0823 19:38:17.999866 14094 solver.cpp:406]     Test net output #16000000: prob = 4.3998e-07
I0823 19:38:18.201782 14094 solver.cpp:406]     Test net output #17000000: prob = 3.9105e-07
I0823 19:38:18.657975 14094 solver.cpp:228] Iteration 7000, loss = 0.293674
I0823 19:38:18.657996 14094 solver.cpp:245]     Train net output #0: loss = 0.293673 (* 1 = 0.293673 loss)
I0823 19:38:38.553418 14094 sgd_solver.cpp:106] Iteration 7000, lr = 1e-06
I0823 19:48:08.169001 14094 solver.cpp:228] Iteration 7050, loss = 0.33416
I0823 19:48:08.169075 14094 solver.cpp:245]     Train net output #0: loss = 0.33416 (* 1 = 0.33416 loss)
I0823 19:48:28.158767 14094 sgd_solver.cpp:106] Iteration 7050, lr = 1e-06
